第三章

![image](images/frontdot.jpg)

三氯苯酚

传输控制协议(正式名称为 TCP/IP，但在本书的其余部分都称为 TCP)是互联网的主力。它于 1974 年首次定义，建立在互联网协议(IP，在第 1 章中描述)的数据包传输技术之上，让应用程序使用连续的数据流进行通信。除非连接因为网络问题而终止或冻结，否则 TCP 保证数据流将完好无损地到达，不会丢失、复制或打乱任何信息。

携带文档和文件的协议几乎总是建立在 TCP 之上。这包括将网页发送到您的浏览器、文件传输以及所有主要的电子邮件传输机制。TCP 也是人们或计算机之间进行长时间对话的协议选择的基础，例如 SSH 终端会话和许多流行的聊天协议。

当互联网还比较年轻的时候，通过在 UDP 上构建一个应用程序(参见[第 2 章](02.html))并自己仔细选择每个单独数据报的大小和时间，有时很容易试图从网络中挤出更多的性能。但是现代 TCP 实现往往是复杂的，受益于 30 多年的改进、创新和研究。除了协议设计专家，很少有人能改进现代 TCP 栈的性能。如今，甚至像消息队列这样的性能关键型应用程序([第 8 章](08.html))通常也选择 TCP 作为它们的媒介。

TCP 如何工作

正如你在第一章和第二章[中了解到的，网络是变化无常的生物。它们有时会丢弃您试图通过它们传输的数据包。他们偶尔会创建数据包的额外副本。此外，它们经常不按顺序发送数据包。对于 UDP 这样的简单数据报工具，您自己的应用程序代码必须考虑每个数据报是否到达，并在没有到达时制定恢复计划。但是使用 TCP，数据包本身隐藏在协议之下，您的应用程序可以简单地将数据流向其目的地，确信丢失的信息将被重新传输，直到它最终成功到达。](02.html)

TCP/IP 的经典定义是 1981 年的 RFC 793，尽管许多后续的 RFC 都有详细的扩展和改进。

TCP 如何提供可靠的连接？以下是它的基本原则:

*   每个 TCP 数据包都有一个序列号，这样接收端的系统就可以按正确的顺序将它们放回一起，还可以注意到序列中丢失的数据包，并要求重新传输它们。
*   代替使用连续的整数(1，2，3...)为了对数据包进行排序，TCP 使用一个计数器来计算传输的字节数。例如，序列号为 7，200 的 1，024 字节的数据包后面会跟一个序列号为 8，224 的数据包。这意味着繁忙的网络堆栈不需要记住它是如何将数据流分解成数据包的。如果请求重传，它可以通过其他方式将数据流分成新的数据包(如果现在有更多的字节等待传输，这可能会让数据包容纳更多的数据)，而接收器仍然可以将数据包重新组合在一起。
*   在好的 TCP 实现中，初始序列号是随机选择的，这样恶棍就不能假定每个连接都从字节 0 开始。不幸的是，可预测的序列号使得伪造数据包变得更容易，这些数据包看起来像是数据的合法部分，可能会中断对话。
*   TCP 不是在发送下一个数据包之前需要对每个数据包进行确认，从而在锁定步骤中运行得非常慢，而是在等待响应之前一次发送整个数据包突发。在任何给定时刻，发送者愿意在网络上传输的数据量被称为 TCP *窗口*的大小。
*   接收端的 TCP 实现可以调整发送端的窗口大小，从而减慢或暂停连接。这被称为*流量控制*。这使得接收器在其输入缓冲区已满的情况下禁止传输额外的数据包，即使数据到达，它也必须丢弃更多的数据。
*   最后，如果 TCP 认为数据包正在被丢弃，它会认为网络正在变得拥塞，并减少每秒发送的数据量。这对于无线网络和其他介质来说可能是一场灾难，在这些介质中，数据包仅仅因为噪声而丢失。它还会破坏正常运行的连接，直到路由器重启，端点无法通话，比如说 20 秒。当网络恢复时，两个 TCP 对等体将会认为网络的流量已经超负荷了，在重新建立联系时，它们将首先拒绝以除涓涓细流之外的任何方式向对方发送数据。

TCP 的设计除了刚才描述的行为之外，还涉及许多其他细微差别和细节，但理想情况下，这种描述会让您对它的工作方式有一个良好的感觉——尽管您会记得，您的应用程序看到的只是一个数据流，实际的数据包和序列号被您的操作系统网络堆栈巧妙地隐藏了起来。

何时使用 TCP

如果你的网络程序和我的完全一样，那么你从 Python 执行的大部分网络通信将使用 TCP。事实上，您可能在整个职业生涯中都没有刻意从您的代码中生成 UDP 包。(不过，正如你将在第 5 章中看到的，每当你的程序需要查找 DNS 主机名时，UDP 可能会出现在后台。)

尽管当两个互联网程序需要通信时，TCP 几乎已经成为通用的默认协议，但我将介绍一些它的行为不是最佳的实例，以防您正在编写的应用程序属于这些类别之一。

首先，TCP 是一种笨拙的协议，在这种协议中，客户端希望向服务器发送单个的、小的请求，然后它们就完成了，不会再与服务器进一步对话。两台主机建立 TCP 连接需要三个数据包，即著名的 SYN、SYN-ACK 和 ACK 序列。

*   *SYN* :“我想说话；这是我将开始使用的数据包序列号。”
*   SYN-ACK :“好的，这是我将在我的方向上使用的初始序列号。”
*   *ACK* :“好的！”

当连接完成时，需要另外三个或四个数据包来关闭连接——要么是快速 FIN、FIN-ACK 和 ACK，要么是每个方向上一对稍长的单独 FIN 和 ACK 数据包。总之，至少需要六个数据包来传递一个请求！在这种情况下，协议设计者很快转向 UDP。

但是，有一个问题要问，客户机是否想打开一个 TCP 连接，然后用它在几分钟或几小时内向同一台服务器发出许多单独的请求。一旦连接开始并且支付了握手的成本，每个实际的请求和响应在每个方向上只需要一个包，这将受益于 TCP 关于重传、指数补偿和流量控制的所有智能。

UDP 真正的优势在于客户机和服务器之间不存在长期的关系，特别是在客户机太多的情况下，如果必须为每个活动客户机提供单独的数据流，典型的 TCP 实现就会耗尽内存。

TCP 不适用的第二种情况是，当数据包丢失时，应用程序可以做一些比简单地重新传输数据更聪明的事情。例如，想象一个音频聊天对话。如果一秒钟的数据因为丢包而丢失，那么简单地一遍又一遍地重新发送同样一秒钟的音频，直到它最终到达，也没有什么好处。相反，客户端应该用它可以从确实到达的数据包中拼凑的任何音频来填充这尴尬的一秒钟(一个聪明的音频协议将使用来自前后时刻的一点高度压缩的音频来开始和结束每个数据包，以准确地覆盖这种情况)，然后在中断后继续进行，就像它没有发生一样。这对于 TCP 来说是不可能的，它会顽固地重新传输丢失的信息，即使这些信息已经太旧而没有任何用处。UDP 数据报通常是互联网上实时流媒体的基础。

TCP 套接字是什么意思

正如 UDP 在第 2 章中的情况一样，TCP 使用端口号来区分在同一 IP 地址上运行的不同应用程序，并且它遵循关于众所周知的短暂端口号的完全相同的约定。如果您想查看详细信息，请重读该章中的“端口号”一节。

正如您在上一章中看到的，只需要一个套接字就可以发出 UDP:一个服务器可以打开一个 UDP 端口，然后从成千上万个不同的客户端接收数据报。虽然当然有可能将数据报套接字`connect()`到一个特定的对等体，使得套接字总是只`send()`到该对等体和从该对等体发回的`recv()`数据包，但是连接的概念只是为了方便。`connect()`的效果与您的应用程序简单地自行决定只向一个地址发送`sendto()`呼叫，然后忽略来自同一地址以外的任何地址的响应是完全一样的。

但是对于像 TCP 这样的有状态流协议，`connect()`调用成为所有进一步网络通信的开端。这是操作系统的网络堆栈启动上一节描述的握手协议的时刻，如果成功，TCP 流的两端都可以使用。

这意味着 TCP `connect()`与 UDP 套接字上的相同调用不同，可能会失败。远程主机可能不应答，或者拒绝连接。或者可能发生更模糊的协议错误，如立即接收到 RST(“复位”)分组。因为流连接涉及在两台主机之间建立持久连接，所以另一台主机需要监听并准备好接受您的连接。

在“服务器端”——根据定义，会话伙伴不执行`connect()`调用，而是接收 connect 调用发起的 SYN 包——传入的连接为 Python 应用程序生成了一个更重要的事件:创建一个新的套接字！这是因为 TCP 的标准 POSIX 接口实际上涉及两种完全不同的套接字:“被动”监听套接字和主动“连接”套接字。

*   *被动* *套接字* 或*监听* *套接字* 维护服务器准备接收连接的“套接字名称”——地址和端口号。这种套接字不能接收或发送任何数据。它不代表任何实际的网络对话。相反，它是服务器如何首先提醒操作系统它愿意在给定的 TCP 端口号上接收传入的连接。
*   一个活动的、*连接的* *套接字* 被绑定到一个具有特定 IP 地址和端口号的特定远程会话伙伴。它只能用于与那个伙伴来回通话，而且它可以被读取和写入，而不用担心产生的数据如何被分割成包。流看起来非常像管道或文件，在 Unix 系统上，一个连接的 TCP 套接字可以传递给另一个希望从普通文件中读取的程序，而该程序甚至永远不会知道它正在通过网络进行对话。

请注意，虽然被动套接字通过它正在侦听的接口地址和端口号变得唯一(不允许任何其他人获取相同的地址和端口)，但是可以有许多主动套接字共享相同的本地套接字名称。例如，一个繁忙的 web 服务器，有一千个客户端都与它建立了 HTTP 连接，它将有一千个活动套接字都绑定到 TCP 端口 80 的公共 IP 地址。活动套接字的独特之处在于四部分坐标，如下所示:

```
(local_ip, local_port, remote_ip, remote_port)
```

正是这个四元组，操作系统通过它来命名每个活动的 TCP 连接，并且检查传入的 TCP 包以查看它们的源地址和目的地址是否将它们与系统上任何当前活动的套接字相关联。

一个简单的 TCP 客户端和服务器

看一下[清单 3-1](#list1) 。正如我在前一章所做的，我在这里将两个独立的程序合并成一个清单——因为它们共享一些公共代码，这样客户端和服务器代码可以更容易地一起阅读。

[***清单 3-1***](#_list1) 。简单的 TCP 服务器和客户端

```
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter03/tcp_sixteen.py
# Simple TCP client and server that send and receive 16 octets

import argparse, socket

def recvall(sock, length):
    data = b''
    while len(data) < length:
        more = sock.recv(length - len(data))
        if not more:
            raise EOFError('was expecting %d bytes but only received'
                           ' %d bytes before the socket closed'
                           % (length, len(data)))
        data += more
    return data

def server(interface, port):
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    sock.bind((interface, port))
    sock.listen(1)
    print('Listening at', sock.getsockname())
    while True:
        sc, sockname = sock.accept()
        print('We have accepted a connection from', sockname)
        print('  Socket name:', sc.getsockname())
        print('  Socket peer:', sc.getpeername())
        message = recvall(sc, 16)
        print('  Incoming sixteen-octet message:', repr(message))
        sc.sendall(b'Farewell, client')
        sc.close()
        print('  Reply sent, socket closed')

def client(host, port):
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.connect((host, port))
    print('Client has been assigned socket name', sock.getsockname())
    sock.sendall(b'Hi there, server')
    reply = recvall(sock, 16)
    print('The server said', repr(reply))
    sock.close()

if __name__ == '__main__':
    choices = {'client': client, 'server': server}
    parser = argparse.ArgumentParser(description='Send and receive over TCP')
    parser.add_argument('role', choices=choices, help='which role to play')
    parser.add_argument('host', help='interface the server listens at;'
                        ' host the client sends to')
    parser.add_argument('-p', metavar='PORT', type=int, default=1060,
                        help='TCP port (default 1060)')
    args = parser.parse_args()
    function = choices[args.role]
    function(args.host, args.p)
```

在第二章的[中，我非常仔细地讨论了`bind()`](02.html) 的主题，因为你作为参数提供的地址做出了一个重要的选择:它决定了远程主机是否可以尝试连接到我们的服务器，或者你的服务器是否受到保护，不能与外部连接，只能被运行在同一台机器上的其他程序联系。相应地，[第 2 章](02.html)从仅将自己绑定到环回接口的安全程序列表开始，然后发展到接受来自网络上其他主机的连接的更危险的程序列表。

但是在这里，我将两种可能性合并到一个清单中。使用您从命令行提供的`host`参数，您可以更安全地选择绑定到 127.0.0.1，或者您可以选择绑定到您机器的一个外部 IP 地址——或者您可以提供一个空字符串来表示您将接受您机器的任何 IP 地址的连接。再次，如果你想记住所有的规则，回顾一下第二章，这些规则同样适用于 TCP 和 UDP 连接和套接字。

您选择的端口号也与您在第 2 章中为 UDP 选择端口号时具有相同的权重，同样，TCP 和 UDP 在端口号主题上的对称性非常相似，您可以简单地应用您在那里使用的推理来理解为什么在本章中使用了相同的选择。

那么，UDP 的早期成果与构建在 TCP 之上的新客户端和服务器之间有什么区别呢？

客户实际上看起来差不多。它创建一个套接字，用它想要与之通信的服务器的地址运行`connect()`，然后就可以自由地发送和接收数据了。但除此之外，还有几个不同之处。

首先，TCP `connect()` 调用——正如我刚才所讨论的——不是本地套接字配置的无关紧要的部分，它在 UDP 的情况下仅仅设置一个默认的远程地址，用于任何后续的`send()`或`recv()`调用。这里，`connect()`是一个真实的实时网络操作，它启动客户机和服务器之间的三次握手，以便它们准备好进行通信。这意味着`connect()`可能会失败，因为您可以在服务器不运行时通过执行客户端来轻松验证。

```
$ python tcp_deadlock.py client localhost
Sending 16 bytes of data, in chunks of 16 bytes
Traceback (most recent call last):
  ...
ConnectionRefusedError: [Errno 111] Connection refused
```

第二，您将看到这个 TCP 客户端在某种程度上比 UDP 客户端简单得多，因为它不需要为丢弃的数据包做任何准备。由于 TCP 提供的保证，它可以`send()`数据，甚至不用停下来检查远程端是否接收到它，并且运行`recv()`而不必考虑重新传输其请求的可能性。客户端可以放心，网络堆栈将执行任何必要的重新传输，以使其数据通过。

第三，这个程序实际上比等效的 UDP 代码更复杂——这可能会让你感到惊讶，因为尽管有它的保证，对程序员来说，TCP 流似乎比 UDP 数据报更简单。但是正因为 TCP 认为你的输出和输入数据只是没有开始和结束的数据流，所以它可以随心所欲地把它们分成包。因此`send()`和`recv()` 的含义与之前有所不同。在 UDP 的情况下，它们仅仅意味着“发送这个数据报”或“接收一个数据报”，每个数据报都是原子的:它要么到达，要么不是一个自包含的数据单元。应用程序永远不会看到只发送了一半或接收了一半的 UDP 数据报。只有完整的数据报才会被传送到 UDP 应用程序。

但是 TCP 可能会在传输过程中将其数据流拆分成几个不同大小的数据包，然后在接收端逐渐重新组合它们。尽管对于[清单 3-1](#list1) 中的 16 个八位字节的小消息来说，这几乎是不可能的，但是您的代码仍然需要为这种可能性做好准备。对于`send()`和`recv()`呼叫，TCP 流的结果是什么？

从考虑`send()`开始。当你执行一个 TCP `send()` 时，你的操作系统的网络堆栈将面临三种情况之一。

*   数据可以立即被本地系统的网络堆栈接受，要么是因为网卡可以立即自由传输，要么是因为系统有空间将数据复制到一个临时的传出缓冲区，以便您的程序可以继续运行。在这些情况下，`send()`立即返回，并且它将返回数据字符串的长度作为其返回值，因为整个字符串正在被传输。
*   另一种可能是，网卡正忙，此套接字的传出数据缓冲区已满，系统无法(或不愿)分配更多空间。在这种情况下，`send()`的默认行为只是阻塞，暂停你的程序，直到数据可以被接受传输。
*   还有最后一种中间可能性:输出缓冲区*几乎*满了，但还没有满，所以你试图发送的数据的*部分*可以立即排队。但是数据块的其余部分将不得不等待。在这种情况下，`send()`会立即完成，并返回从数据字符串开始处接受的字节数，但不会处理其余的数据。

由于最后一种可能性，您不能简单地在流套接字上调用`send()`而不检查返回值。您必须将一个`send()`调用放入一个循环中，在部分传输的情况下，这个循环将继续尝试发送剩余的数据，直到整个字节串都被发送完。有时，您会看到在网络代码中使用如下所示的循环来表达这一点:

```
bytes_sent = 0
while bytes_sent < len(message):
    message_remaining = message[bytes_sent:]
    bytes_sent += s.send(message_remaining)
```

幸运的是，Python 不会在每次有数据块要发送的时候强迫您自己跳这种舞。作为一个特殊的便利，标准库`socket`实现提供了一个友好的`sendall()`方法`()` ，清单 3-1 使用了这个方法[。`sendall()`不仅比自己做要快，因为它是用 C 实现的，而且(对于那些知道这意味着什么的读者来说)它在循环期间释放了全局解释器锁，这样其他 Python 线程可以无争用地运行，直到所有数据都被传输完。](#list1)

不幸的是，没有为`recv()`调用提供等效的标准库包装器，尽管它也有不完全传输的可能。在内部，`recv()` 的操作系统实现使用的逻辑非常接近发送时使用的逻辑。

*   如果没有数据可用，那么`recv()`阻塞，你的程序暂停，直到数据到达。
*   如果传入缓冲区中已经有足够的数据可用，那么您将获得与您给予`recv()`的许可一样多的字节。
*   如果缓冲区只包含*一些*等待数据，但没有你允许`recv()`返回的那么多，那么你会立即返回那里发生的事情，即使它没有你请求的那么多。

这就是为什么`recv()`调用必须在一个循环中。操作系统无法知道这个简单的客户机和服务器正在使用固定宽度的 16 位字节消息。因为它不能猜测输入的数据何时最终会达到你的程序所认为的一个完整的消息，所以它会尽可能快地给你任何数据。

为什么 Python 标准库包含了`sendall()`却没有`recv()`方法的等价物？这可能是因为如今固定长度的消息非常少见。大多数协议对于如何分隔传入流的一部分有着复杂得多的规则，而不是简单的“消息总是 16 字节长”的决定在大多数现实世界的程序中，运行`recv()`的循环要比清单 3-1 中的[更复杂，因为一个程序经常要读取或处理部分消息，然后才能猜测还会有多少消息。例如，一个 HTTP 响应由头、一个空行组成，然后在`Content-Length`头中指定了更多字节的数据。您不知道要运行多少次`recv()`,直到您至少收到了头，然后解析它们以找出内容长度，这种细节最好留给您的应用程序，而不是标准库。](#list1)

每个对话一个套接字

转到清单 3-1 中的服务器代码，你会看到一个与你之前看到的非常不同的模式，这种差异取决于 TCP 流套接字的真正含义。回想一下我们之前的讨论，有两种不同类型的流套接字:*监听*套接字，服务器使用它们为传入的连接提供一个端口，以及*连接*套接字，它们代表服务器与特定客户端的对话。

在清单 3-1 中，你可以看到这种区别是如何在实际的服务器代码中实现的。这个链接可能会让您觉得奇怪，因为侦听套接字实际上会返回一个新的、连接的套接字，作为您通过调用`accept()`获得的值！让我们按照程序清单中的步骤来看看套接字操作发生的顺序。

首先，服务器运行`bind()` 来声明一个特定的端口。请注意，这还不能决定程序是客户端还是服务器，也就是说，它是主动建立连接还是被动等待接收传入的连接。它只是声明一个特定的端口，或者在一个特定的接口上，或者在所有的接口上，供这个程序使用。如果出于某种原因，客户端希望从其机器上的特定端口访问服务器，而不是简单地使用分配给它们的临时端口号，那么它们也可以使用这个调用。

真正的决策时刻伴随着下一个方法调用，当服务器宣布它想要使用套接字到`listen()` 。在 TCP 套接字上运行它完全改变了它的特性。在调用了`listen()`之后，套接字被不可撤销地改变了，并且从这一点开始，再也不能被用来发送或接收数据。这个特定的套接字对象现在永远不会连接到任何特定的客户端。相反，套接字现在只能用于通过其`accept()`方法接收传入的连接——这种方法你在本书中还没有见过，因为它的目的只是支持监听 TCP 套接字——这些调用中的每一个都等待新的客户端连接，然后返回一个全新的*新的*套接字，该套接字控制刚刚与它们开始的新对话。

从代码中可以看出，`getsockname()`对监听和连接的套接字都很有效，在这两种情况下，它都可以让您找出套接字使用的本地 TCP 端口。要了解一个已连接的套接字所链接到的客户机的地址，您可以在任何时候运行`getpeername()` 方法，或者您可以存储作为第二个返回值从`accept()`返回的套接字名称。当您运行此服务器时，您会看到两个值为您提供了相同的地址。

```
$ python tcp_sixteen.py server ""
Listening at ('0.0.0.0', 1060)
Waiting to accept a new connection
We have accepted a connection from ('127.0.0.1', 57971)
  Socket name: ('127.0.0.1', 1060)
  Socket peer: ('127.0.0.1', 57971)
  Incoming sixteen-octet message: b'Hi there, server'
  Reply sent, socket closed
Waiting to accept a new connection
```

让客户端与服务器建立一个连接，就像这样，产生了前面的输出:

```
$ python3 tcp_sixteen.py client 127.0.0.1
Client has been assigned socket name ('127.0.0.1', 57971)
The server said b'Farewell, client'
```

您可以从其余的服务器代码中看到，一旦连接的套接字被`accept()`返回，它就像客户端套接字一样工作，在它们的通信模式中没有进一步的不对称性。当数据变得可用时，`recv()`调用返回数据，当您想确保所有数据都被传输时，`sendall()`是发送整个数据块的最佳方式。

您会注意到，当在服务器套接字上调用`listen()`时，向它提供了一个整数参数。这个数字表明，在操作系统开始忽略新的连接并推迟任何进一步的三次握手之前，应该允许多少个等待的连接(这些连接还没有被`accept()`调用创建套接字)进行堆叠。我在示例中使用非常小的值`1`，因为我一次只支持一个示例客户端连接，但是当我在第 7 章中谈到网络服务器设计时，我会考虑更大的值。

一旦客户机和服务器完成了它们需要的一切，它们就`close()`告诉操作系统传输仍然留在输出缓冲区中的任何剩余数据，然后通过前面提到的 FIN-packet 关闭过程结束 TCP 会话。

地址已被使用

在[清单 3-1](#list1) 中还有最后一个你可能会好奇的细节。为什么服务器在尝试绑定到端口之前会小心翼翼地设置套接字选项`SO_` `REUSEADDR` ？

如果您注释掉该行，然后尝试运行服务器，就可以看到未能设置该选项的后果。起初，你可能认为这没有什么后果。如果您所做的只是停止和启动服务器，那么您将看不到任何效果(这里我启动服务器，然后在终端的提示下用一个简单的 Ctrl+C 终止它):

```
$ python tcp_sixteen.py server ""
Listening at ('127.0.0.1', 1060)
Waiting to accept a new connection
^C
Traceback (most recent call last):
  ...
KeyboardInterrupt
$ python tcp_sixteen.py server ""
Listening at ('127.0.0.1', 1060)
Waiting to accept a new connection
```

但是，如果您启动服务器，对其运行客户机，然后尝试终止并重新运行服务器，您会看到很大的不同。当服务器开始备份时，您将收到一条错误消息:

```
$ python tcp_sixteen.py server
Traceback (most recent call last):
  ...
OSError: [Errno 98] Address already in use
```

多么神秘！为什么一个可以一遍又一遍重复的`bind()`会仅仅因为一个客户端已经连接而突然变得不可能？如果您继续尝试在没有`SO_REUSEADDR`选项的情况下运行服务器，您会发现该地址直到您最后一次连接客户端几分钟后才再次可用。

这种限制的原因是操作系统的网络堆栈非常小心。仅仅在监听的服务器套接字可以立即关闭并被遗忘。但是，一个连接的 TCP 套接字(实际上是在与客户机对话)不会立即消失，即使客户机和服务器可能都关闭了它们的连接并在每个方向上发送 FIN 数据包。为什么呢？因为即使在网络堆栈发送了关闭套接字的最后一个数据包之后，它也无法确定是否收到了该数据包。如果它碰巧被网络丢弃，那么远程终端可能在任何时候都想知道是什么用了这么长时间才发送最后一个包，并重新发送它的 FIN 包，希望最终收到一个应答。

像 TCP 这样可靠的协议显然必须有这样一个停止说话的点；从逻辑上来说，一些最后的包必须被挂起而不被确认，否则系统将不得不承诺无休止的交换“好吧，我们都同意我们都完成了，对吗？”消息，直到机器最终被关闭。然而，即使是最后一个数据包也可能会丢失，需要重新传输几次，另一端才能最终收到它。解决办法是什么？

答案是，从应用程序的角度来看，一旦一个已连接的 TCP 连接最终关闭，操作系统的网络堆栈实际上会在等待状态下保存一份长达四分钟的记录。RFC 将这些状态命名为关闭等待和时间等待。当关闭的套接字仍然处于这些状态中的任何一个时，任何最终的 FIN 分组都可以被正确地应答。如果 TCP 实现只是忘记了连接，那么它就不能用正确的 ACK 回复 FIN。

因此，一个服务器试图声明一个在过去几分钟内正在运行活动连接的端口，实际上是试图声明一个在某种意义上仍在使用的端口。这就是为什么如果你尝试一个`bind()`到那个地址，你会返回一个错误。通过指定套接字选项`SO_REUSEADDR`，您表明您的应用程序可以拥有一个端口，该端口的旧连接可能仍然在网络上的某个客户端上关闭。实际上，我在编写服务器代码时总是使用`SO_REUSEADDR`,从来没有遇到过任何问题。

绑定到接口

正如我在第二章讨论 UDP 时所解释的，当你执行`bind()`操作时，你与一个端口号配对的 IP 地址告诉操作系统你希望从哪个网络接口接收连接。清单 3-1 中[的示例调用使用了本地 IP 地址 127.0.0.1，这可以保护您的代码免受来自其他机器的连接。](#list1)

您可以通过在服务器模式下运行[清单 3-1](#list1) 来验证这一点，如前所示，并尝试从另一台机器连接客户机。

```
$ python tcp_sixteen.py client 192.168.5.130
Traceback (most recent call last):
  ...
ConnectionRefusedError: [Errno 111] Connection refused
```

您可以看到，如果您让服务器运行，它甚至没有反应。操作系统甚至不会通知它到其端口的传入连接被拒绝。(请注意，如果您的计算机上运行了防火墙，客户端在尝试连接时可能会挂起，而不是得到友好的“连接被拒绝”异常来告诉它正在发生什么！)

但是，如果您使用空字符串作为主机名来运行服务器，这将告诉 Python `bind()`例程您愿意接受通过您机器的任何活动网络接口的连接，那么客户端可以从另一台主机成功连接(空字符串是通过在命令行末尾给 shell 加上这两个双引号来提供的)。

```
$ python tcp_sixteen.py server ""
Listening at ('0.0.0.0', 1060)
Waiting to accept a new connection
We have accepted a connection from ('127.0.0.1', 60359)
  Socket name: ('127.0.0.1', 1060)
  Socket peer: ('127.0.0.1', 60359)
  Incoming sixteen-octet message: b'Hi there, server'
  Reply sent, socket closed
Waiting to accept a new connection
```

如前所述，我的操作系统使用特殊的 IP 地址 0.0.0.0 来表示“接受任何接口上的连接”，但这种约定在您的操作系统上可能有所不同，Python 通过让您使用空字符串来隐藏这种差异。

僵局

术语*死锁*用于计算机科学中的各种情况，在这些情况下，共享有限资源的两个程序可能因为糟糕的计划而永远等待对方。事实证明，在使用 TCP 时，这种情况很容易发生。

我前面提到过，典型的 TCP 栈使用缓冲区，这样它们就有地方放置传入的数据包数据，直到应用程序准备好读取它，并且它们可以收集传出的数据，直到网络硬件准备好传输传出的数据包。这些缓冲区的大小通常非常有限，系统通常不愿意让程序用未发送的网络数据填满所有的 RAM。毕竟，如果远程端还没有准备好处理数据，那么花费系统资源来生成更多的数据是没有意义的。

如果你遵循[清单 3-1](#list1) 中所示的客户端-服务器模式 ，这种限制通常不会给你带来麻烦，在这种模式中，每一端总是在转身向另一个方向发送数据之前读取其伙伴的完整消息。但是，如果您设计的客户机和服务器让太多的数据等待，而没有及时读取这些数据的安排，那么您很快就会遇到麻烦。

看看[清单 3-2](#list2) 中的一个例子，一个服务器和客户端不考虑后果就试图变得有点聪明。在这里，服务器作者做了一些实际上相当聪明的事情。服务器的工作是将任意数量的文本转换成大写字母。认识到客户端请求可以任意大，并且在尝试处理输入流之前尝试读取整个输入流可能会耗尽内存，服务器一次读取和处理 1，024 字节的小数据块。

[***清单 3-2***](#_list2) 。可能死锁的 TCP 服务器和客户端

```
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter03/tcp_deadlock.py
# TCP client and server that leave too much data waiting

import argparse, socket, sys

def server(host, port, bytecount):
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    sock.bind((host, port))
    sock.listen(1)
    print('Listening at', sock.getsockname())
    while True:
        sc, sockname = sock.accept()
        print('Processing up to 1024 bytes at a time from', sockname)
        n = 0
        while True:
            data = sc.recv(1024)
            if not data:
                break
            output = data.decode('ascii').upper().encode('ascii')
            sc.sendall(output)  # send it back uppercase
            n += len(data)
            print('\r  %d bytes processed so far' % (n,), end=' ')
            sys.stdout.flush()
        print()
        sc.close()
        print('  Socket closed')

def client(host, port, bytecount):
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    bytecount = (bytecount + 15) // 16 * 16  # round up to a multiple of 16
    message = b'capitalize this!'  # 16-byte message to repeat over and over

    print('Sending', bytecount, 'bytes of data, in chunks of 16 bytes')
    sock.connect((host, port))

    sent = 0
    while sent < bytecount:
        sock.sendall(message)
        sent += len(message)
        print('\r  %d bytes sent' % (sent,), end=' ')
        sys.stdout.flush()

    print()
    sock.shutdown(socket.SHUT_WR)

    print('Receiving all the data the server sends back')

    received = 0
    while True:
        data = sock.recv(42)
        if not received:
            print('  The first data received says', repr(data))
        if not data:
            break
        received += len(data)
        print('\r  %d bytes received' % (received,), end=' ')

    print()
    sock.close()

if __name__ == '__main__':
    choices = {'client': client, 'server': server}
    parser = argparse.ArgumentParser(description='Get deadlocked over TCP')
    parser.add_argument('role', choices=choices, help='which role to play')
    parser.add_argument('host', help='interface the server listens at;'
                        ' host the client sends to')
    parser.add_argument('bytecount', type=int, nargs='?', default=16,
                        help='number of bytes for client to send (default 16)')
    parser.add_argument('-p', metavar='PORT', type=int, default=1060,
                        help='TCP port (default 1060)')
    args = parser.parse_args()
    function = choices[args.role]
    function(args.host, args.p, args.bytecount)
```

它可以很容易地分割工作——不需要做框架或分析——因为它只是试图在普通 ASCII 字符上运行`upper()`字符串方法。这是一个可以在每个输入块上单独执行的操作，而不用担心之前或之后的块。如果服务器试图运行像`title()`这样更复杂的字符串操作，事情就不会这么简单了，如果单词碰巧跨越了块边界而没有正确地重新组合，那么这个字符串操作就会在单词中间大写字母。例如，如果一个特定的数据流被分割成 16 字节的块，那么错误就会像这样出现:

```
>>> message = 'the tragedy of macbeth'
>>> blocks = message[:16], message[16:]
>>> ''.join(b.upper() for b in blocks)   # works fine
'THE TRAGEDY OF MACBETH'
>>> ''.join(b.title() for b in blocks)   # whoops
'The Tragedy Of MAcbeth'
```

在固定长度的块 上分割的同时处理文本也不适用于 UTF-8 编码的 Unicode 数据，因为多字节字符可能会在两个二进制块之间的边界上分割。在这种情况下，服务器必须比这个例子更加小心，并且在一个数据块和下一个数据块之间传递某种状态。

在任何情况下，像这样一次处理一个块的输入对于服务器来说都是非常智能的，即使这里用于说明的 1，024 字节的块大小对于今天的服务器和网络来说实际上是一个非常小的值。通过分段处理数据并立即发送响应，服务器限制了每次必须保存在内存中的数据量。这样设计的服务器可以同时处理数百台客户机，每台客户机发送的数据流总计数千兆字节，而不会增加内存或其他硬件资源的负担。

对于小数据流，清单 3-2 中的客户端和服务器看起来工作得很好。如果您启动服务器，然后使用指定适度字节数的命令行参数运行客户端，比如说，要求它发送 32 字节的数据，那么它将获得全部大写的文本。为简单起见，它会将您提供的任何值四舍五入到 16 字节的倍数。

```
$ python tcp_deadlock.py client 127.0.0.1 32
Sending 32 bytes of data, in chunks of 16 bytes
  32 bytes sent
Receiving all the data the server sends back
  The first data received says b'CAPITALIZE THIS!CAPITALIZE THIS!'
  32 bytes received
```

服务器将报告它确实代表其最近的客户端处理了 32 个字节。顺便说一下，服务器需要运行在同一台机器上，这个脚本使用本地主机 IP 地址来使示例尽可能简单。

```
Processing up to 1024 bytes at a time from ('127.0.0.1', 60461)
  32 bytes processed so far
  Socket closed
```

因此，当用少量数据测试时，这段代码看起来工作得很好。事实上，它也可能适用于更大的数量。尝试用数百或数千字节运行客户端，看看它是否继续工作。

顺便说一下，第一个数据交换示例向您展示了我之前描述的`recv()`的行为。即使服务器要求接收 1，024 个字节，如果这是可用的数据量，并且还没有来自客户端的数据，那么`recv(1024)`也很乐意只返回 16 个字节。

但是这个客户端和服务器可能会被推到可怕的境地。如果你尝试一个足够大的值，那么灾难就来了！试着使用客户端发送一个大的数据流，比如说，一个总计 1gb 的数据流。

```
$ python tcp_deadlock.py client 127.0.0.1 1073741824
```

您将看到客户端和服务器都在紧张地更新它们的终端窗口，它们气喘吁吁地向您更新它们发送和接收的数据量。这些数字会不断攀升，直到突然之间，两个连接都冻结了。实际上，如果您仔细观察，您会看到服务器首先停止，然后客户端很快停止。在我写这一章的 Ubuntu 笔记本电脑上，在它们停止之前处理的数据量各不相同，但是在我刚刚在我的笔记本电脑上完成的测试运行中，Python 脚本停止了，服务器说:

```
$ python tcp_deadlock.py server ""
Listening at ('0.0.0.0', 1060)
Processing up to 1024 bytes at a time from ('127.0.0.1', 60482)
  4452624 bytes processed so far
```

并且客户端在写入其输出数据流时被冻结了大约 350，000 字节。

```
$ python tcp_deadlock.py client "" 16000000
Sending 16000000 bytes of data, in chunks of 16 bytes
  8020912 bytes sent
```

为什么客户端和服务器都停止了？

答案是服务器的输出缓冲区和客户机的输入缓冲区最终都已填满，TCP 使用其窗口调整协议来通知这一事实，并阻止套接字发送额外的数据，这些数据将被丢弃并在以后重新发送。

为什么这会导致僵局？考虑每个数据块传输时会发生什么。客户端用`sendall()`发送。然后服务器通过`recv()`接受它，处理它，并通过另一个`sendall()`调用将它的大写版本传输回来。然后呢。嗯，没什么！客户端*从不*运行任何`recv()`调用——当它仍有数据要发送时——因此越来越多的数据备份，直到操作系统缓冲区不再愿意接受更多数据。

在前面显示的运行过程中，在网络堆栈确定客户端的传入队列已满之前，操作系统在其中缓冲了大约 4MB。在这一点上，服务器阻塞了它的`sendall()`调用，它的进程被操作系统暂停，直到阻塞被清除，它可以发送更多的数据。随着服务器不再处理数据或运行更多的`recv()`调用，现在轮到客户机开始备份数据了。操作系统似乎已经将它愿意在该方向排队的数据量限制在 3.5MB 左右，因为客户端在最终停止之前已经大致产生了数据。

在你自己的系统上，你可能会发现达到了不同的极限；上述数字是任意的，基于我的笔记本电脑此刻的心情。它们根本不是 TCP 工作方式所固有的。

这个例子的目的是教你两件事——当然，除此之外，显示如果立即可用的字节数更少，那么`recv(1024)`确实返回少于 1，024 的字节数！

首先，这个例子应该使网络连接两端的 TCP 栈中有缓冲区 的想法更加具体。这些缓冲区可以临时保存数据，这样，如果数据包到达时，它们的读取器恰好不在`recv()`调用内，就不会被丢弃并最终被重新发送。但是缓冲区不是无限的。最终，试图写入从未被接收或处理的数据的 TCP 例程将发现自己不再能够写入，直到一些数据最终被读取并且缓冲区开始变空。

第二，这个例子清楚地表明了协议 中包含的危险，这些协议没有交替锁定步骤，客户端请求有限数量的数据，然后等待服务器应答或确认。如果一个协议没有严格要求服务器读取一个完整的请求，直到客户端完成发送，然后在另一个方向发送一个完整的响应，那么像这里创建的情况可能会导致两者都冻结，除了手动终止程序，然后重写它以改进它的设计。

但是，网络客户机和服务器应该如何处理大量数据 而不进入死锁呢？事实上，有两种可能的答案。首先，他们可以使用套接字选项来关闭阻塞，这样像`send()`和`recv()`这样的调用如果发现它们还不能发送任何数据，就会立即返回。你将在第 7 章的[中了解到更多关于这个选项的信息，在那里你将认真地寻找构建网络服务器程序的可能方法。](07.html)

或者，程序可以使用几种技术中的一种来一次处理来自几个输入的数据，或者通过分成单独的线程或进程(一个任务是将数据发送到套接字，另一个任务是将数据读取回来)，或者通过运行操作系统调用，如`select()`或`poll()`，让它们同时等待繁忙的传出和传入套接字，并对准备好的套接字做出响应。这些也将在[第 7 章](07.html)中探讨。

最后，请注意，当您使用 UDP 时，上述情况永远不会发生。这是因为 UDP 不实现流量控制。如果到达的数据报多于可以处理的数据报，那么 UDP 可以简单地丢弃其中一些数据报，让应用程序去发现它们丢失了。

封闭连接、半开连接

从前面的例子中可以看出，在另一个不同的问题上，还有两点需要说明。

首先，[清单 3-2](#list2) 向您展示了当到达文件结尾时 Python 套接字对象的行为。就像 Python 文件对象在没有剩余数据时返回一个空字符串一样，套接字在关闭时只返回一个空字符串。

在清单 3-1 中，我从不担心这个问题，因为在那种情况下，我对协议施加了足够严格的结构——交换一对正好 16 字节的消息——当通信完成时，我不需要关闭套接字来发送信号。客户机和服务器可以发送消息，同时让套接字保持打开状态，稍后再关闭它们的套接字，而不用担心有人在等待它们关闭。

但是在[清单 3-2](#list2) 中，客户端发送——因此服务器也处理并发回——任意数量的数据，其长度仅由用户在命令行输入的数字决定。所以你可以在代码中看到两次相同的模式:一个`while`循环，一直运行到最后看到一个从`recv()`返回的空字符串。注意，一旦到达第 7 章的[并探索非阻塞套接字，这种正常的 Pythonic 模式将不再工作，其中`recv()`可能仅仅因为此刻没有可用的数据而引发异常。在这种情况下，使用其他技术来确定套接字是否已经关闭。](07.html)

其次，您将看到客户端在发送完传输后，在套接字上发出一个 `shutdown()`调用。这解决了一个重要问题。如果服务器将一直读取，直到看到文件结束，那么客户端将如何避免在套接字上执行完整的`close()`操作，从而禁止自己运行许多`recv()`调用来接收服务器的响应呢？解决方案是“半关闭”套接字——也就是说，在不破坏套接字本身的情况下永久关闭一个方向的通信。在这种状态下，服务器不能再读取任何数据，但是它仍然可以在另一个方向上发送任何剩余的回复，该方向仍然是开放的。

如清单 3-2 中的[所示，`shutdown()`调用可以用来结束双向套接字中的任何一个方向的通信。它的参数可以是三个符号之一。](#list2)

*   这是最常用的值，因为在大多数情况下，程序知道自己的输出何时完成，但不一定知道它的对话伙伴何时结束。这个值表示调用者将不再向套接字写入数据，从另一端读取的数据应该响应没有更多数据并指示文件结束。
*   `SHUT_RD`:这用于关闭传入的套接字流，这样，如果您的对等方试图在套接字上向您发送更多数据，就会遇到文件结束错误。
*   `SHUT_RDWR`:关闭套接字上的双向通信。起初，这可能看起来没什么用，因为您也可以只在套接字上执行一个`close()`,并且通信在两个方向上都是类似地结束的。关闭一个套接字和双向关闭套接字之间的区别是相当高级的。如果你的操作系统上的几个程序被允许共享一个套接字，那么`close()`仅仅是结束你的进程与套接字的关系，但是只要另一个进程还在使用它，它就保持打开。另一方面，`shutdown()`方法总是会立即禁用每个使用它的人的套接字。

由于不允许通过标准的`socket()`调用创建单向套接字，许多只需要在一个套接字上单向发送信息的程序员会先创建它，然后——一旦连接上了——立即运行`shutdown()`,向他们不需要的方向发送。这意味着，如果与之通信的对等体意外地试图以不应该的方向发送数据，操作系统缓冲区不会被不必要地填满。

在应该是单向的套接字上立即运行`shutdown()`,还会为混淆并试图发送数据的对等体提供更明显的错误消息。否则，意外数据要么会被忽略，要么甚至会填满缓冲区并导致死锁，因为它永远不会被读取。

像文件一样使用 TCP 流

由于 TCP 支持数据流，它们可能已经让您想起了普通文件，普通文件也支持读写顺序数据作为基本操作。Python 很好地将这些概念分开。文件对象可以`read()`和`write()`，而套接字只能`send()`和`recv()`。没有一种物体能同时做到这两点。(与底层 POSIX 接口相比，这实际上是一个更干净、更可移植的概念划分，它允许 C 程序员不加区别地调用套接字上的`read()`和`write()`，就像它是一个普通的文件描述符一样。)

但是有时候你会想把一个套接字当作一个普通的 Python 文件对象——通常是因为你想把它传递给这样的代码，像很多 Python 模块，比如`pickle`、`json`和`zlib`，可以直接从文件中读写数据。为此，Python 在每个返回 Python 文件对象的套接字上提供了一个`makefile()`方法，该对象真正在幕后调用`recv()`和`send()`。

```
>>> import socket
>>> sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
>>> hasattr(sock, 'read')
False
>>> f = sock.makefile()
>>> hasattr(f, 'read')
True
```

像 Ubuntu 和 Mac OS X 这样的 Unix 衍生系统上的套接字，像普通的 Python 文件一样，也有一个`fileno()`方法，让您发现它们的文件描述符编号，以防您需要将它提供给低级调用。当你在第 7 章的[中探索`select()`和`poll()`时，你会发现这很有帮助。](07.html)

摘要

TCP 驱动的“流”套接字做任何必要的事情，包括重新传输丢失的数据包，重新排序无序到达的数据包，以及将大量数据流拆分为适合您的网络的最佳大小的数据包，以支持两个套接字之间的网络数据流的传输和接收。

与 UDP 一样，TCP 使用端口号来区分可能存在于一台机器上的许多流端点。想要接受传入的 TCP 连接的程序需要`bind()`到一个端口，在套接字上运行`listen()`，然后进入一个循环，该循环反复运行`accept()`来为每个传入的连接接收一个新的套接字，通过该套接字它可以与每个连接的特定客户端对话。想要连接到现有服务器端口的程序只需要创建一个套接字和一个地址的`connect()`。

服务器通常希望在它们的套接字上设置选项，以免服务器最后一次运行时在同一个端口上关闭的旧连接阻止操作系统允许绑定。

使用`send()`和`recv()`实际发送和接收数据。一些运行在 TCP 之上的协议会标记它们的数据，以便客户端和服务器自动知道通信何时完成。其他协议将 TCP 套接字视为真正的流，并发送和接收，直到到达文件结尾。`shutdown()`套接字方法可用于在一个套接字上产生一个方向的文件结束(所有套接字本质上都是双向的)，同时保持另一个方向开放。

如果两个对等体被写入，使得套接字填充越来越多的永远不会被读取的数据，则会发生死锁。最终，一个方向将不再能够`send()`并可能永远等待积压清除。

如果你想把一个套接字传递给一个知道如何读写普通文件对象的 Python 例程，`makefile()` socket 方法会给你一个 Python 对象，当调用者需要读写时，这个对象会在后台调用`recv()`和`send()`。