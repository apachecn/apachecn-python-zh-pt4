第十一章

![image](img/frontdot.jpg)

万维网

第 9 章和[第 10 章](10.html)将超文本传输协议(HTTP)解释为一种通用机制，通过这种机制，客户机可以请求文档，服务器可以通过提供文档来响应。

然而，有些事情无法解释。为什么协议的名字以*超文本*这个词开头？

答案是 HTTP 不仅仅是作为一种传输文件的新方法而设计的。它不仅仅是 FTP 之类的旧文件传输协议的花哨的缓存替代品(见第 17 章)。虽然它当然能够传送独立的文档，如书籍、图像和视频，但 HTTP 的目的更为远大:允许世界各地的服务器发布文档，通过相互交叉引用，这些文档成为一个单一的相互链接的信息结构。

HTTP 是为传送万维网而建立的。

超媒体和 URL

几千年来，书籍一直引用其他书籍。但是人类必须通过获取另一本书并翻页直到找到引用的文本来制定每个引用。万维网(WWW，或简称“Web”)实现的梦想是将解析引用的责任委托给机器。

当惰性文本如“第九章第一节中关于 cookies 的讨论”在电脑屏幕上变成下划线并可点击时，点击会将你带到它所引用的文本，它就变成了一个*超链接*。其文本可以包含嵌入超链接的完整文档被称为*超文本*文档。当图像、声音和视频被添加到混音中时，用户正在体验*超媒体*。

在每种情况下，前缀 *hyper-* 表示介质本身理解文档相互引用的方式，并且可以为用户建立这些链接。印刷书籍中的“参见第 103 页”这句话本身并没有力量带你到达它所描述的目的地。相比之下，显示超链接的浏览器确实有这种能力。

为了给超媒体提供动力，发明了统一资源定位符(URL) 。它提供了一个统一的方案，通过这个方案，不仅现代的超文本文档，甚至旧的 FTP 文件和 Telnet 服务器都可以被引用。你已经在网络浏览器的地址栏中看到了很多这样的例子。

```py
# Some sample URLs

https://www.python.org/
http://en.wikipedia.org/wiki/Python_(programming_language)
http://localhost:8000/headers
ftp://ssd.jpl.nasa.gov/pub/eph/planets/README.txt
telnet://rainmaker.wunderground.com
```

像`https`或`http`这样的初始标签是*方案*，它命名了可以检索文档的协议。冒号和两个斜线`://`后面是主机名和可选端口号。最后，*路径*从服务上可能可用的所有文档中选择一个特定的文档。

这种语法可以用于比描述从网络上获取的材料更一般的目的。统一资源标识符(URI) 的更一般的概念可以用于识别物理网络可访问的文档，或者作为通用的唯一标识符，用于给概念实体提供计算机可读的名称，即被称为统一资源名称(urn)的标签。这本书里的所有内容都是一个 URL。

对了，*网址*的发音是 *you-are-ell* 。“伯爵”是英国贵族中的一员，其级别不完全是侯爵，但确实高于子爵——所以伯爵相当于欧洲大陆上的伯爵(换句话说，不是网络文档地址)。

当基于用户指定的参数自动生成一个文档时，该 URL 用一个 *查询字符串* 扩展，该查询字符串以一个问号(`?`)开始，然后使用&符号(`&`)来分隔每个进一步的参数。每个参数由名称、等号和值组成。

```py
https://www.google.com/search?q=apod&btnI=yes
```

最后，URL 可以以一个*片段*作为后缀，该片段命名了链接所指向的页面上的特定位置。

```py
http://tools.ietf.org/html/rfc2324#section-2.3.2
```

片段不同于 URL 的其他组成部分。因为 web 浏览器假定它需要获取由路径命名的整个页面，以便找到由片段命名的元素，所以它实际上并不在其 HTTP 请求中传输片段！当服务器获取一个 HTTP URL 时，它能从浏览器获知的只有主机名、路径和查询。您可能还记得第 9 章中的主机名，它是作为主机头发送的，路径和查询被连接在一起，产生完整的路径，该路径遵循请求第一行中的 HTTP 方法。

如果你研究 RFC 3986，你会发现一些很少使用的附加特性。当您遇到想要了解更多的罕见特性时，可以参考这个权威资源，比如在 URL 本身中包含一个`user@password`认证字符串的可能性。

解析并构建 URL

Python 标准库中内置的 `urllib.parse`模块提供了解释和构建 URL 所需的工具。将一个 URL 拆分成多个组成部分是一个函数调用。它返回的内容在 Python 的早期版本中只是一个元组，您仍然可以以这种方式查看结果，并使用整数索引(或赋值语句中的元组解包)来访问它的项。

```py
>>> from urllib.parse import urlsplit
>>> u = urlsplit('https://www.google.com/search?q=apod&btnI=yes')
>>> tuple(u)
('https', 'www.google.com', '/search', 'q=apod&btnI=yes', '')
```

但是 tuple 还支持对其项目的命名属性访问，以帮助您在检查 URL 时提高代码的可读性。

```py
>>> u.scheme
'https'
>>> u.netloc
'www.google.com'
>>> u.path
'/search'
>>> u.query
'q=apod&btnI=yes'
>>> u.fragment
''
```

“网络位置”`netloc`可以有几个从属片段，但是它们很少见，所以`urlsplit()`不会将它们作为单独的条目放在元组中。相反，它们只能作为结果的属性。

```py
>>> u = urlsplit('https://brandon:atigdng@localhost:8000/')
>>> u.netloc
'brandon:atigdng@localhost:8000'
>>> u.username
'brandon'
>>> u.password
'atigdng'
>>> u.hostname
'localhost'
>>> u.port
8000
```

将一个 URL 化整为零只是解析过程的一半。路径和查询组件都可以包含在成为 URL 的一部分之前必须转义的字符。例如，`&`和`#`不能按字面意思出现，因为它们分隔了 URL 本身。如果字符`/`出现在特定的路径组件中，则需要对其进行转义，因为斜杠用于分隔路径组件。

URL 的查询部分有自己的编码规则。查询值通常包含空格——想想你在谷歌中输入的所有包含空格的搜索——因此加号`+`被指定为查询中空格编码的替代方式。否则，查询字符串只能选择像 URL 的其余部分一样对空格进行编码，作为一个`%20`十六进制转义码。

为了访问“TCP/IP”部分并在那里搜索有关“数据包丢失”的信息，解析正在访问您站点的“Q&A”部分的 URL 的唯一正确方法如下:

```py
>>> from urllib.parse import parse_qs, parse_qsl, unquote
>>> u = urlsplit('http://example.com/Q%26A/TCP%2FIP?q=packet+loss')
>>> path = [unquote(s) for s in u.path.split('/')]
>>> query = parse_qsl(u.query)
>>> path
['', 'Q&A', 'TCP/IP']
>>> query
[('q', 'packet loss')]
```

注意，我使用`split()`对路径进行的分割返回了一个初始的空字符串，因为这个特定的路径是一个以斜杠开头的绝对路径。

查询以元组列表的形式给出，而不是简单的字典，因为 URL 查询字符串允许多次指定查询参数。如果您正在编写不关心这种可能性的代码，您可以将元组列表传递给`dict()`，您将只看到每个参数的最后一个值。如果您想要回一个字典，但也想让一个参数被多次指定，那么您可以从`parse_qsl()`切换到`parse_qs()`，并取回一个值为列表的字典。

```py
>>> parse_qs(u.query)
{'q': ['packet loss']}
```

标准库提供了从另一个方向返回的所有必要的例程。给定前面显示的`path`和`query`，Python 可以通过引用每个路径组件、用斜线将它们重新连接在一起、对查询进行编码并将结果呈现给“unsplit”例程(与前面调用的`urlsplit()`函数相反)来从 URL 的各个部分重建 URL。

```py
>>> from urllib.parse import quote, urlencode, urlunsplit
>>> urlunsplit(('http', 'example.com',
...           '/'.join(quote(p, safe='') for p in path),
...           urlencode(query), ''))
'http://example.com/Q%26A/TCP%2FIP?q=packet+loss'
```

如果您仔细地将所有的 URL 解析委托给这些标准的库例程，您会发现完整规范的所有微小细节都为您考虑到了。

前面例子中的代码是如此的完全正确，以至于一些程序员甚至会把它描述为大惊小怪，甚至过度紧张。实际上，路径组件本身有多长时间有斜线？大多数网站都小心翼翼地设计路径元素，开发人员称之为 *slugs* ，这样它们就不需要丑陋的转义出现在 URL 中。如果一个网站只允许 URL 段包含字母、数字、破折号和下划线，那么担心段本身包含斜杠显然是错误的。

如果您确定您正在处理的路径在单个路径组件中从来没有转义斜杠，那么您可以简单地将整个路径暴露给`quote()`和`unquote()`，而不必先将其拆分。

```py
>>> quote('Q&A/TCP IP')
'Q%26A/TCP%20IP'
>>> unquote('Q%26A/TCP%20IP')
'Q&A/TCP IP'
```

事实上，`quote()`例程认为这是常见的情况，因此它的参数默认值是`safe='/'`，通常不会改变斜线。这就是被`safe=''`在繁琐的代码版本中覆盖的内容。

标准库`urllib.parse`模块有几个比之前概述的通用例程更专门的例程，包括用于在`#`字符处将 URL 从其片段中分离出来的`urldefrag()`。阅读文档以了解这个函数和其他函数，这些函数可以使一些特殊情况变得更加方便。

相对网址

您的文件系统命令行支持“更改工作目录”命令，该命令确定了系统将开始搜索*相对*路径的位置，该路径缺少前导斜杠。以斜杠开头的路径明确声明它们从文件系统的根开始搜索。它们是*绝对的*路径，不管你的工作目录是什么，它们总是命名同一个位置。

```py
$ wc -l /var/log/dmesg
977 dmesg
$ wc -l dmesg
wc: dmesg: No such file or directory
$ cd /var/log
$ wc -l dmesg
977 dmesg
```

超文本也有同样的概念。如果文档中的所有链接都是绝对 URL，就像上一节中的那样，那么它们链接到的资源就没有问题。但是，如果文档包含相对 URL，那么就必须考虑文档自己的位置。

Python 提供了一个`urljoin()`例程，它理解整个标准的所有细微差别。给定一个从超文本文档中恢复的 URL，它可能是相对的，也可能是绝对的，您可以将它传递给`urljoin()`来填充任何缺失的信息。如果 URL 是绝对的，没问题；它将被原封不动地退回。

`urljoin()`的参数顺序与`os.path.join()`相同。首先提供您正在检查的文档的基本 URL，然后提供您在其中找到的 URL。有几种不同的方法可以重写相对 URL 的基本部分。

```py
>>> from urllib.parse import urljoin
>>> base = 'http://tools.ietf.org/html/rfc3986'
>>> urljoin(base, 'rfc7320')
'http://tools.ietf.org/html/rfc7320'
>>> urljoin(base, '.')
'http://tools.ietf.org/html/'
>>> urljoin(base, '..')
'http://tools.ietf.org/'
>>> urljoin(base, '/dailydose/')
'http://tools.ietf.org/dailydose/'
>>> urljoin(base, '?version=1.0')
'http://tools.ietf.org/html/rfc3986?version=1.0'
>>> urljoin(base, '#section-5.4')
'http://tools.ietf.org/html/rfc3986#section-5.4'
```

同样，为`urljoin()`提供一个绝对 URL 是绝对安全的，因为它会检测到它是完全自包含的，并在不修改基本 URL 的情况下返回它。

```py
>>> urljoin(base, 'https://www.google.com/search?q=apod&btnI=yes')
'https://www.google.com/search?q=apod&btnI=yes'
```

相对 URL 使得编写不知道是由 HTTP 还是 HTTPS 提供服务的网页变得容易，即使在页面的静态部分也是如此，因为相对 URL 可以省略模式，但指定其他所有内容。在这种情况下，只有方案是从基本 URL 复制的。

```py
>>> urljoin(base, '//www.google.com/search?q=apod')
'http://www.google.com/search?q=apod'
```

如果你的站点要使用相对 URL，那么你必须严格控制页面是否带有斜杠，因为相对 URL 有两种不同的含义，取决于是否有斜杠。

```py
>>> urljoin('http://tools.ietf.org/html/rfc3986', 'rfc7320')
'http://tools.ietf.org/html/rfc7320'
>>> urljoin('http://tools.ietf.org/html/rfc3986/', 'rfc7320')
'http://tools.ietf.org/html/rfc3986/rfc7320'
```

这两个基本 URL 之间的细微差别对于任何相对链接的意义来说都是至关重要的！第一个 URL 可以被认为是访问了`html`目录，以便显示它在那里找到的`rfc3986`文件，这使得“当前工作目录”成为了`html`目录。相反，第二个 URL 将`rfc3986`本身视为它正在访问的目录，因为在真正的文件系统中，只有目录可以带一个尾随斜杠。因此，构建在第二个 URL 之上的相对链接从`rfc3986`组件开始构建，而不是从它的父组件`html`开始构建。

总是设计你的网站，让用户到达一个以错误方式书写的 URL 时，可以立即被重定向到正确的路径。例如，如果您试图访问前一个示例中的第二个 URL，那么 IETF web 服务器将检测到错误的尾部斜杠，并在其响应中声明一个带有正确 URL 的 Location: header。

如果您曾经编写过 web 客户端，这是一个教训:相对 URL 是*而不是*相对于您在 HTTP 请求中提供的路径！如果站点选择用一个位置头来响应，那么相对 URL 应该相对于那个可替换的位置来构造。

超文本标记语言

有很多关于推动网络发展的核心文档格式的书籍。还有描述超文本文档格式本身的活动标准、用层叠样式表(CSS) 对其进行样式化的可用机制，以及当用户与文档交互或从服务器检索更多信息时，浏览器嵌入语言(如 JavaScript (JS ))可以通过其对文档进行实时更改的 API。核心标准和资源如下:

```py
http://www.w3.org/TR/html5/
http://www.w3.org/TR/CSS/
https://developer.mozilla.org/en-US/docs/Web/JavaScript
https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model
```

由于这是一本网络编程的书，我将把我的注意力限制在这些技术涉及网络的方式上。

*超文本标记语言* (HTML) 是一种使用几乎不合理数量的尖括号对纯文本进行修饰的方案——也就是说，小于号和大于号`<...>`被重新映射为开括号和闭括号。每对尖括号创建一个*标签*，它或者在文档中打开一个新的*元素*，或者用一个初始斜杠表示它关闭了一个先前打开的元素。一个简单的段落，一个单词用粗体，另一个用斜体，可能如下所示:

```py
<p>This is a paragraph with <b>bold</b> and <i>italic</i> words.</p>
```

一些标签是独立的，而不需要相应的结束标签出现在后面——最著名的是，标签`<br>`创建了一个段落中间的换行符。更谨慎的作者将其作为自结束标记`<br/>`输入，这是他们从可扩展标记语言(XML) 中学来的习惯，但是 HTML 使其成为可选的。

事实上，HTML 让很多事情变得可选，包括适当的结束标签。当一个`<ul>`无序列表元素结束时，一致性解析器也将理解它一直在读取的特定列表元素`<li>`现在也被关闭和结束，无论是否遇到实际的`</li>`标签。

前面给出的示例段落清楚地表明 HTML 是同心的。设计者可以将元素放在其他元素的内部，就像他们构建一个完整的网页一样。随着设计人员的构建，他们几乎不可避免地会重用 HTML 为页面上的不同目的而定义的有限集合中的元素。尽管新的 HTML5 标准允许在页面中间即时创建新元素，但设计师倾向于坚持使用标准元素。

一个大页面可能会使用一个通用的标签，比如 `<div>`(这是最通用的一种框)或`<span>`(标记运行文本的最通用方式)，分别用于十几个不同的目的。当所有的`<div>`元素都是完全相同的标签时，CSS 如何恰当地设计每个元素的样式，JavaScript 如何让用户与它们进行不同的交互？

答案是 HTML 作者可以为每个元素指定一个*类*,提供一个更具体的标签，通过这个标签可以对元素进行寻址。有两种使用类的通用方法。

一揽子方法是让设计者为他们设计中的每一个 HTML 元素附加一个独特的类。

```py
<div class="weather">
  <h5 class="city">Provo</h5>
  <p class="temperature">61°F</p>
</div>
```

他们的 CSS 和 JavaScript 可以用类似`.city`和`.temperature`的选择器来引用这些元素，或者，如果他们想更具体一点的话，`h5.city`和`p.temperature`。CSS 选择器最简单的形式是提供一个标记名和一个以句点为前缀的类名，这两者都是可选的。

或者设计者可能会认为一个`<h5>`在他们的天气标志中只有一个目的，一个段落也只有一个目的，所以选择用一个类来装饰外部元素。

```py
<div class="weather"><h5>Provo</h5><p>61°F</p></div>
```

他们现在需要更复杂的模式来指定他们想要的`<h5>`和`<p>`存在于一个`<div>`中，这个类使得它的`<div>`是唯一的。模式是通过空格构建的——将匹配外部标签的模式与内部标签的模式连接起来。

```py
.weather h5
.weather p
```

参考 CSS 标准或 CSS 介绍，了解除了这些简单的可能性之外的所有可用选项。如果您想了解如何使用选择器从浏览器中运行的实时代码中定位元素，还可以阅读 JavaScript 简介或 jQuery 等强大的文档操作库。

你可以通过谷歌 Chrome 或 Firefox 等现代浏览器的两个功能来调查你最喜欢的网站是如何包装信息的。如果你按下 Ctrl+U，它们会向你显示你正在查看的页面的 HTML 代码——语法高亮显示——你可以右击任何元素并选择 Inspect Element 来调出调试工具，让你调查每个文档元素如何与你在页面上看到的内容相关联，如图 11-1 所示。

![9781430258544_Fig11-01.jpg](img/9781430258544_Fig11-01.jpg)

[图 11-1](#_Fig1) 。Google Chrome 中的 Inspect 标签

在检查器中，您可以切换到一个网络选项卡，该选项卡将显示所有其他下载的资源，并显示为访问该页面的结果。

注意，图 11-2 中的[所示的网络面板通常是空的。启动后，单击“重新加载”,查看信息填充情况。](#Fig2)

![9781430258544_Fig11-02.jpg](img/9781430258544_Fig11-02.jpg)

[图 11-2](#_Fig2) 。Google Chrome 网络标签显示下载的渲染 python.org 的资源

请注意，您使用 Inspect Element 调查的实时文档可能与最初作为页面源提供的 HTML 很少或没有相似之处，这取决于 JavaScript 在初始页面加载后是否工作并从页面中添加或删除了元素。如果您在检查器中看到您感兴趣的元素，但在原始源代码中找不到它，您可能需要访问调试器的 Network 选项卡，以确定 JavaScript 正在获取哪些额外的资源，它可能已用于构建这些额外的页面元素。

当您现在开始在随后的程序清单中试验小型 web 应用时，您将希望尽可能使用浏览器的 Inspect Element 特性来检查应用返回的页面。

读取和写入数据库

想象一个简单的银行应用，它希望允许帐户持有人使用 web 应用互相发送付款。至少，这样的应用需要一个付款表，一种插入新付款的方法，以及一种获取所有涉及当前登录用户帐户的付款以便显示的方法。

清单 11-1 展示了一个简单的库，展示了所有这三个特性，它由内置于 Python 标准库中的 SQLite 数据库提供支持。因此，这个清单应该可以在任何安装了 Python 的地方工作！

[***清单 11-1***](#_list1) 。用于构建和与数据库对话的例程

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/bank.py
# A small library of database routines to power a payments application.

import os, pprint, sqlite3
from collections import namedtuple

def open_database(path='bank.db'):
    new = not os.path.exists(path)
    db = sqlite3.connect(path)
    if new:
        c = db.cursor()
        c.execute('CREATE TABLE payment (id INTEGER PRIMARY KEY,'
                  ' debit TEXT, credit TEXT, dollars INTEGER, memo TEXT)')
        add_payment(db, 'brandon', 'psf', 125, 'Registration for PyCon')
        add_payment(db, 'brandon', 'liz', 200, 'Payment for writing that code')
        add_payment(db, 'sam', 'brandon', 25, 'Gas money-thanks for the ride!')
        db.commit()
    return db

def add_payment(db, debit, credit, dollars, memo):
    db.cursor().execute('INSERT INTO payment (debit, credit, dollars, memo)'
                        ' VALUES (?, ?, ?, ?)', (debit, credit, dollars, memo))

def get_payments_of(db, account):
    c = db.cursor()
    c.execute('SELECT * FROM payment WHERE credit = ? or debit = ?'
              ' ORDER BY id', (account, account))
    Row = namedtuple('Row', [tup[0] for tup in c.description])
    return [Row(*row) for row in c.fetchall()]

if __name__ == '__main__':
    db = open_database()
    pprint.pprint(get_payments_of(db, 'brandon'))
```

SQLite 引擎将每个数据库放在磁盘上的单个文件中，因此`open_database()`函数可以检查该文件是否存在，以确定数据库是正在创建还是仅仅被重新打开。在创建数据库时，它构建一个付款表并添加三个付款示例，这样您的 web 应用除了显示一个空的付款列表之外，还会显示一些内容。

该模式过于简单——这是运行该应用的最低要求。在现实生活中，需要有一个用户名和安全密码散列的用户表，以及一个正式的银行账户表，钱可以从那里来，也可以存到那里。这款应用并不现实，而是允许用户在输入时创建示例帐户名。

本例中要研究的一个关键操作是，它的 SQL 调用的所有参数都被正确转义。如今，安全缺陷的一个主要来源是程序员在将特殊字符提交给 SQL 这样的解释型语言时，未能正确地对其进行转义。如果 web 前端的恶意用户想出了一种方法来键入 memo 字段，使其包含特殊的 SQL 代码，该怎么办？最好的保护是依靠数据库本身——而不是您自己的逻辑——来正确引用数据。

[清单 11-1](#list1) 通过在代码需要插值的地方给 SQLite 一个问号(`?`)来正确地做到这一点，而不是试图自己进行任何转义或插值。

另一个关键操作是将原始数据库行混合成更具语义的内容。`fetchall()`方法并不是 sqlite3 独有的，而是所有现代 Python 数据库连接器支持的互操作性的 DB-API 2.0 的一部分。此外，它不会为从数据库返回的每一行返回一个对象，甚至是一个字典。它为每个返回的行返回一个元组。

```py
(1, 'brandon', 'psf', 125, 'Registration for PyCon')
```

处理这些原始元组的结果可能是不幸的。在你的代码中，像“贷记的账户”或“支付的美元数”这样的概念可能会以`row[2]`或`row[3]`的形式出现，很难阅读。因此，`bank.py`转而创建了一个快速命名元组类，这个类也将响应属性名，比如`row.credit`和`row.dollars`。每次调用`SELECT`时创建一个新的类并不是最佳选择，但是在一两行代码中提供了 web 应用代码需要的语义——让您更快地转向 web 应用代码本身。

一个糟糕的 Web 应用(在 Flask 中)

除了阅读下面的程序清单之外，您还可以在下面的几个清单中试验示例 web 应用，方法是查看本章的源代码库:

```py
https://github.com/brandon-rhodes/fopnp
```

您可以在此处浏览特定于本章的文件:

```py
https://github.com/brandon-rhodes/fopnp/tree/m/py3/chapter11
```

您应该研究的第一个文件是`app_insecure.py` ，如[清单 11-2](#list2) 所示。在面对这些问题之前，仔细通读代码是值得的:它看起来像是导致安全妥协和公众耻辱的那种可怕和不可信的代码吗？它看起来危险吗？

[***清单 11-2***](#_list2) 。一个不安全的 Web 应用(不是 Flask 的错！)

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/app_insecure.py
# A poorly-written and profoundly insecure payments application.
# (Not the fault of Flask, but of how we are choosing to use it!)

import bank
from flask import Flask, redirect, request, url_for
from jinja2 import Environment, PackageLoader

app = Flask(__name__)
get = Environment(loader=PackageLoader(__name__, 'templates')).get_template

@app.route('/login', methods=['GET', 'POST'])
def login():
    username = request.form.get('username', '')
    password = request.form.get('password', '')
    if request.method == 'POST':
        if (username, password) in [('brandon', 'atigdng'), ('sam', 'xyzzy')]:
            response = redirect(url_for('index'))
            response.set_cookie('username', username)
            return response
    return get('login.html').render(username=username)

@app.route('/logout')
def logout():
    response = redirect(url_for('login'))
    response.set_cookie('username', '')
    return response

@app.route('/')
def index():
    username = request.cookies.get('username')
    if not username:
        return redirect(url_for('login'))
    payments = bank.get_payments_of(bank.open_database(), username)
    return get('index.html').render(payments=payments, username=username,
        flash_messages=request.args.getlist('flash'))

@app.route('/pay', methods=['GET', 'POST'])
def pay():
    username = request.cookies.get('username')
    if not username:
        return redirect(url_for('login'))
    account = request.form.get('account', '').strip()
    dollars = request.form.get('dollars', '').strip()
    memo = request.form.get('memo', '').strip()
    complaint = None
    if request.method == 'POST':
        if account and dollars and dollars.isdigit() and memo:
            db = bank.open_database()
            bank.add_payment(db, username, account, dollars, memo)
            db.commit()
            return redirect(url_for('index', flash='Payment successful'))
        complaint = ('Dollars must be an integer' if not dollars.isdigit()
                     else 'Please fill in all three fields')
    return get('pay.html').render(complaint=complaint, account=account,
                                  dollars=dollars, memo=memo)

if __name__ == '__main__':
    app.debug = True
    app.run()
```

列表不仅危险，而且容易受到现代网络上活跃的许多最重要的攻击媒介的攻击！通过在本章接下来的几节中研究它的缺点，您将了解到一个应用生存所需要的最基本的防护。这些弱点都是数据处理过程中的错误，与网站是否首先受到 TLS 的适当保护以防止窥探的问题是分开的。你可以继续想象它确实受到加密的保护，也许是通过位于服务器前的反向代理(见[第 10 章](10.html))，因为我将考虑攻击者甚至可以在无法看到特定用户和应用之间的数据传递的情况下做什么。

该应用使用 Flask web 框架来处理作为一个 Python web 应用的基本操作:回答 404 应用没有定义的页面，解析来自 HTML 表单的数据(您将在下面的部分中了解到)，并使编写正确的 HTTP 响应变得容易，这些响应包含来自一个模板的 HTML 文本或重定向到另一个 URL。通过访问`http://flask.pocoo.org/`网站上的 Flask 文档，你可以了解到比本章提到的更多的关于 Flask 的知识。

想象一下，不熟悉 Web 的程序员编写了这个清单。他们听说过模板语言可以很容易地将自己的文本添加到 HTML 中，所以他们想出了如何加载并运行`Jinja2`。此外，他们发现 Flask 微框架的受欢迎程度仅次于 Django，因为 Flask 应用可以放在一个文件中，所以他们决定尝试一下。

从上到下阅读，可以看到一个 `login()`页和一个`logout()`页。因为这个应用没有真正的用户数据库，登录页面只是硬编码了两个可能的用户帐户和密码。稍后您将了解更多关于表单逻辑的内容，但是您已经可以看到，登录和注销的结果是 cookie 的创建和删除(参见第 9 章的[和第 10 章](09.html)的[),当这些 cookie 出现在后续请求中时，会将它们标记为属于特定的认证用户。](10.html)

站点上的其他两个页面通过查找这个 cookie 和重定向回登录页面(如果他们对缺少值不满意)来保护自己免受未授权用户的攻击。除了对登录用户的检查之外,`login()`视图只有两行代码(因为行的长度，只有三行):它从数据库中提取当前用户的付款，并将它们与一些其他信息放在一起提供给 HTML 页面模板。页面可能想知道用户名是有道理的，但是为什么代码要检查名为`'flash'`的消息的 URL 参数(Flask 将其作为`request.args`字典使用)？

如果你读了第 `pay()`页，答案就很明显了。在成功付款的情况下，用户将被重定向到索引页面，但可能希望得到一些指示，表明表单达到了预期的效果。这是由显示在页面顶部的 *flash 消息*提供的，web 框架这样称呼它们。(这个名字与旧的 Adobe Flash 系统写广告没有任何关系，而是指当下一次查看一个页面时，消息“闪现”在用户面前，然后消失)。在这个 web 应用的第一个草案中，flash 消息只是作为 URL 中的一个查询字符串。

```py
http://example.com/?flash=Payment+successful
```

对于 web 应用的读者来说，`pay()`例程的其余部分是熟悉的:检查表单是否已经成功提交，如果已经提交，则执行一些操作。因为用户或浏览器可能已经提供或省略了任何表单参数，所以代码小心翼翼地使用`request.form`字典的`get()`方法寻找它们，如果缺少一个键，该方法可以返回一个默认值(这里是空字符串`''`)。

如果请求令人满意，那么付款将永久添加到数据库中。否则，表单将呈现给用户。如果他们已经完成了输入一些信息的工作，那么代码会小心地不要丢弃这些工作:它不会向他们显示一个空白表单和错误消息来丢弃他们的工作，而是将他们输入的值传递回模板，以便可以重新显示它们。

回顾清单 11-2 中提到的三个 HTML 模板对下一节讨论表单和方法至关重要。实际上有四个模板，因为 HTML 的公共设计元素已经被分解到一个基础模板中，这是构建多页面站点的设计者最常用的模式。

[清单 11-3](#list3) 中的模板定义了一个带有插入点的页面框架，其他模板可以在其中插入页面标题和页面正文。请注意，标题可以使用两次，一次在`<title>`元素中，一次在`<h1>`元素中，这要感谢 Jinja2 模板语言设计得如此之好——由阿明·罗纳切尔编写，他还编写了 Werkzeug(见[第 10 章](10.html))和 Flask。

[***清单 11-3***](#_list3) 。`base.html`页面 Jinja2 模板

```py
<html>
  <head>
    <title>{% block title %}{% endblock %}</title>
    <link rel="stylesheet" type="text/css" href="/static/style.css">
  </head>
  <body>
    <h1>{{ self.title() }}</h1>
    {% block body %}{% endblock %}
  </body>
</html>
```

例如， Jinja2 模板语言决定了双括号语法(如在`{{ username }}`中)是如何要求将一个值替换到模板中的，并且像`{% for %}`这样的括号百分比策略可以用于循环和重复产生相同的 HTML 模式。关于它的语法和特性的更多信息，请参见它在`http://jinja.pocoo.org/`的文档。

清单 11-4 所示的登录页面除了标题和表单本身什么也没有。您可以第一次看到一个您将再次看到的模式:一个表单元素，它提供了一个初始的`value="..."`，当它第一次出现在屏幕上时，应该已经出现在可编辑元素中了。

[***清单 11-4***](#_list4) 。`login.html` Jinja2 模板

```py
{% extends "base.html" %}
{% block title %}Please log in{% endblock %}
{% block body %}
<form method="post">
  <label>User: <input name="username" value="{{ username }}"></label>
  <label>Password: <input name="password" type="password"></label>
  <button type="submit">Log in</button>
</form>
{% endblock %}
```

通过将这个`{{ username }}`替换为`value="..."`，该表单将帮助用户避免在输入错误密码时重新输入用户名，并再次获得相同的表单。

将位于`/`的索引页面在它的模板中有更多的内容，你可以从[清单 11-5](#list5) 中看到。任何简讯，如果有的话，放在标题的正下方。然后出现一个无序列表(`<ul>`)的列表项(`<li>`)，每个列表项描述了登录用户账户的一笔付款，标题为“你的付款”。最后，还有到新支付页面和注销链接的链接。

[***清单 11-5***](#_list5) 。`index.html` Jinja2 模板

```py
{% extends "base.html" %}
{% block title %}Welcome, {{ username }}{% endblock %}
{% block body %}
{% for message in flash_messages %}
  <div class="flash_message">{{ message }}<a href="/">&times;</a></div>
{% endfor %}
<p>Your Payments</p>
<ul>
  {% for p in payments %}
    {% set prep = 'from' if (p.credit == username) else 'to' %}
    {% set acct = p.debit if (p.credit == username) else p.credit %}
    <li class="{{ prep }}">${{ p.dollars }} {{ prep }} <b>{{ acct }}</b>
    for: <i>{{ p.memo }}</i></li>
  {% endfor %}
</ul>
<a href="/pay">Make payment</a> | <a href="/logout">Log out</a>
{% endblock %}
```

注意，代码对一遍又一遍地显示当前用户的帐户名称不感兴趣，因为它循环显示他们的收入和支出。因此，对于每笔付款，它会计算出`credit`或`debit`账户名称是否与当前用户匹配，然后确保打印另一个账户名称——使用正确的介词，这样用户就可以知道他们的钱流向了哪里。这要感谢 Jinja2 的`{% set ... %}`命令，当设计者意识到他们想要什么时，这使得像这样的快速小演示计算很容易在模板中完成。

用户似乎经常有几十种方法不能正确填写表单，清单 11-6 准备好接收一个`complaint`字符串，以便在表单顶部突出显示，如果提供了这样的字符串的话。除此之外，代码大部分是重复的:如果表单填写不正确，需要重新显示三个表单字段，当用户尝试提交表单时，需要用用户已经存在的文本进行预填充。

[***清单 11-6***](#_list6) 。`pay.html` Jinja2 模板

```py
{% extends "base.html" %}
{% block title %}Make a Payment{% endblock %}
{% block body %}
<form method="post" action="/pay">
  {% if complaint %}<span class="complaint">{{ complaint }}</span>{% endif %}
  <label>To account: <input name="account" value="{{ account }}"></label>
  <label>Dollars: <input name="dollars" value="{{ dollars }}"></label>
  <label>Memo: <input name="memo" value="{{ memo }}"></label>
  <button type="submit">Send money</button> | <a href="/">Cancel</a>
</form>
{% endblock %}
```

在网站的每个提交按钮旁边都有一条退路是一个最佳实践。实验表明，如果退路明显比提交表单的默认动作小且不重要，用户犯的错误最少——尤其重要的是，退路*而不是*看起来像按钮！

因此，`pay.html`小心翼翼地使它的“取消”退出路径成为一个简单的链接，通过当前在这种视觉上下文中流行的常规管道符号(`|`)在视觉上与按钮分开。

如果您想尝试这个应用，您可以检查源代码，进入包含`bank.py`、`app_insecure.py`和相关联的`templates/`目录的`chapter11`目录，并键入以下内容:

```py
$ pip install flask
$ python3 app_insecure.py
```

结果应该是一个声明，它已经启动并运行在一个 URL 上，它将打印到您的屏幕上。

```py
* Running on http://127.0.0.1:5000/
* Restarting with reloader
```

打开调试模式后(参见清单 11-2 中[的倒数第二行)，如果你编辑其中一个清单，Flask 甚至会自动重启并重新加载你的应用，这使得快速探索代码的微小变化的效果变得很容易。](#list2)

这里少了一个小细节。如果[清单 11-3](#list3) 中的 `base.html`提到了`style.css`，在哪里？它位于`static/`目录中，您可以在源代码库中的应用旁边找到。如果你发现你不仅对网络编程感兴趣，而且对网页设计的想法感兴趣，你会想要复习一下。

表单和 HTTP 方法之舞

HTML 表单的默认动作是 GET，它可以简单到只有一个输入字段。

```py
<form action="/search">
  <label>Search: <input name="q"></label>
  <button type="submit">Go</button>
</form>
```

本书没有篇幅来讨论表单设计——一个充满技术决策的庞大主题。除了像这里这样的文本字段之外，还有十几种输入要考虑。甚至文本字段周围也有许多选项。您是否打算使用 CSS3 向输入字段添加一些示例文本，当用户开始输入时，这些文本就会消失？在用户输入搜索词之前，浏览器内的 JavaScript 代码是否应该让提交按钮变灰？你应该在输入框下面放一些说明或者一些示例搜索词来给用户提供建议吗？提交按钮应该说“提交”还是说表单提交到服务器后会发生什么？极简设计者会要求你完全省略 Go 按钮，简化网站，但要求用户知道他们可以点击 Return 提交搜索吗？

但是这些问题在关于网页设计的书籍和网站上都有详细的介绍。这本书只能关注形式对网络意味着什么。

执行 GET 的表单将输入字段直接放在 URL 中，从而放在随 HTTP 请求传输的路径中。

```py
GET /search?q=python+network+programming HTTP/1.1
Host: example.com
```

想想这意味着什么。GET 的参数成为你的浏览器历史的一部分，任何人越过你的肩膀看浏览器的地址栏都能看到。这意味着 GET 永远不能用于传递敏感信息，如密码或凭证。当你填写 GET 表单时，你是在陈述“我下一步想去哪里？”您实际上是在帮助浏览器为您希望服务器创建的页面编写一个手工制作的 URL，以便您可以访问它。用三个不同的短语填写之前的搜索表单将导致创建三个单独的页面，三个您可以稍后返回的浏览器历史记录条目，以及三个可以与朋友共享的 URL(如果您希望他们看到相同的结果页面)。

执行 GET 请求的表单就是你如何请求去某个地方，仅仅通过描述你的目的地。

这与相反类型的 HTML 表单形成了鲜明的对比，后者的方法是 POST、PUT 或 DELETE。对于这些表单，表单中的任何信息都不会进入 URL，也不会进入 HTTP 请求中的路径。

```py
<form method="post" action="/donate">
  <label>Charity: <input name="name"></label>
  <label>Amount: <input name="dollars"></label>
  <button type="submit">Donate</button>
</form>
```

当提交这个 HTML 表单时，浏览器将数据完整地放入请求的主体中，而完全不考虑路径。

```py
POST /donate HTTP/1.1
Host: example.com
Content-Type: application/x-www-form-urlencoded
Content-Length: 39
name=PyCon%20scholarships&dollars=35
```

在这里，你不是被动地要求去访问一个“35 美元的 PyCon 奖学金”网页，因为你有兴趣看它。恰恰相反。你承诺了一个行动——如果你决定执行两次帖子而不是一次，这个行动将会花费两倍的钱，产生两倍的影响。表单参数没有放在 URL 中，因为“$35 for PyCon scholarships”不是您想去的地方的名称。这就是已故哲学家 J.L. Austin 所说的一种*言语行为*，即在世界上引起一种新的事态的话语。

顺便说一下，有一种基于 MIME 标准的替代形式编码*multipart/forms*([第 12 章](12.html))，浏览器可以使用它来上传大型有效载荷，如整个文件。然而，无论哪种方式，POST 表单的语义都是相同的。

Web 浏览器对 POST 非常谨慎，因为他们认为这是一个动作。如果用户在查看 POST 返回的页面时试图点击 Reload，浏览器会用一个对话框打断他们。如果您从[清单 11-2](#list2) 中调出 web 应用，访问它的`/pay`表单，然后不输入任何内容就提交表单，这样它会立即返回抱怨“美元必须是整数”当我点击谷歌浏览器中的重新加载时，会弹出一个对话框。

```py
Confirm Form Resubmission

The page that you're looking for used information that you entered. Returning to the page might cause any action you took to be repeated. Do you want to continue?
```

您应该会在自己的浏览器中看到类似的警告。在用肉眼看表单的同时，可以清楚地看到表单 submit 似乎并没有生效；但是浏览器无法知道帖子没有产生效果。它发送了一个帖子，收到了一个页面，据它所知，页面上写着“感谢您捐赠 1000 美元”，再次提交的效果可能是灾难性的。

网站可以使用两种技术来避免用户滞留在一个由帖子引起的页面上，这样会给用户浏览器的重新加载和前进后退按钮带来无尽的麻烦。

*   使用 JavaScript 或 HTML5 表单输入约束，首先尝试防止用户提交无效值。如果在表单准备好提交之前，submit 按钮没有亮起，或者如果整个表单往返过程可以用 JavaScript 处理，而不需要重新加载页面，那么无效的提交——比如您刚才提交的空表单——不会使用户陷入 POST 结果中。
*   当表单最终被正确提交并且动作成功时，web 应用应该抵制诱惑，不要直接用一个 200 OK 的页面来描述完成的动作。相反，用 303 See Other 重定向到 Location 头中指定的另一个 URL 来响应。这将迫使浏览器在成功发布后立即获取，将用户带到其他地方。用户现在可以点击 Reload、Forward 和 Back 来查看自己喜欢的内容，这样只能安全地重复获得结果页面，而不是重复尝试提交表单。

虽然[清单 11-2](#list2) 中的简单应用过于简单，无法在表单无效的情况下屏蔽用户查看 POST 结果，但是当`/login`表单或`/pay`表单成功时，它至少执行了一次成功的 303 See(也由 Flask `redirect()`构造函数提供支持)。这是一个最佳实践，您应该可以在所有 web 框架中找到支持。

当表单使用错误的方法时

滥用 HTTP 方法的 Web 应用会导致自动化工具、用户期望和浏览器出现问题。

我记得有一个朋友，他的小企业网页存储在一家本地托管公司自己开发的 PHP 内容管理系统中。一个管理界面向他展示了他的网站上使用的图片链接。我们突出显示了这个页面，并要求浏览器下载所有的链接，这样他就有了自己的图像备份。几分钟后，他收到了一个朋友的短信:为什么所有的图片都从他的网站上消失了？

事实证明，每张图片旁边的删除按钮，唉，并不是一个真正的启动 POST 操作的按钮。相反，每次删除仅仅是一个普通旧网址的链接，如果你访问它，就会有删除图片的副作用！他的浏览器愿意获取页面上的上百个链接，因为在任何情况下，获取都应该是安全的操作。他的托管公司背叛了这种信任，结果是他的网站不得不从他们的备份中恢复。

相反的错误——用 POST 执行“读取”操作——产生的后果不那么可怕。它只是破坏了可用性，而不是删除你所有的文件。

我曾经不喜欢使用一个大型机构内部开发的搜索引擎。经过几次搜索，我面前有一页结果需要我的主管查看，所以我突出显示了 URL，并准备将其粘贴到电子邮件中。

然后我看了网址，很沮丧。即使不知道服务器是如何工作的，我也确信当我的主管访问它的时候,`/search.pl`不会自己把这一页结果带回来！

我的浏览器地址栏看不到该查询，因为搜索表单被错误地设计为使用 POST。这使得每一个搜索的 URL 看起来完全一样，这意味着搜索既不能共享也不能加书签。当我试图用浏览器的前进和后退按钮浏览一系列搜索时，我得到了一系列弹出窗口，询问我是否真的想重新提交每个搜索！就浏览器所知，这些帖子都可能有副作用。

使用 GET for places 和 POST for actions 是至关重要的，这不仅是为了协议，也是为了高效的用户体验。

安全和不安全的 cookie

清单 11-2 中的[web 应用试图为其用户提供隐私。它需要一个成功的登录，然后才能泄露用户的支付列表，以响应对`/`页面的获取。它还要求用户在接受向`/pay`表单发送的允许用户转账的帖子之前登录。](#list2)

不幸的是，利用该应用并代表另一个用户进行支付是非常容易的！

考虑一下恶意用户在获得站点访问权后可能采取的步骤，也许是在站点上打开自己的帐户来调查它是如何工作的。他们将在 Firefox 或 Google Chrome 中打开调试工具，然后登录到该网站，在网络窗格中观察传出和传入的标头，以了解该网站是如何工作的。他们的用户名和密码会得到什么样的回应？

```py
HTTP/1.0 302 FOUND
...
Set-Cookie: username=badguy; Path=/
...
```

多有趣啊！他们的成功登录将一个名为`username`的 cookie 发送到他们的浏览器，其值为他们自己的用户名`badguy`。显然，该网站很高兴地相信，随后用这个 cookie 发出的请求一定表明他们已经正确地输入了用户名和密码。

但是调用者可以给这个 cookie 任何他们想要的值吗？

他们可以尝试通过点击浏览器中正确的隐私菜单来伪造 cookie，或者尝试从 Python 访问该站点。使用请求，他们可能会先看看是否能获取首页。不出所料，未经身份验证的请求会被转发到`/login`页面。

```py
>>> import requests
>>> r = requests.get('http://localhost:5000/')
>>> print(r.url)
http://localhost:5000/login
```

但是，如果坏人插入一个 cookie，让它看起来像是`brandon`用户已经登录了，该怎么办呢？

```py
>>> r = requests.get('http://localhost:5000/', cookies={'username': 'brandon'})
>>> print(r.url)
http://localhost:5000/
```

成功！因为站点相信它设置了这个 cookie 的值，所以它现在响应 HTTP 请求，就像它们来自另一个用户一样。坏人只需要知道支付系统的另一个用户的用户名，他们就可以伪造一个请求，将钱汇往他们想去的任何地方。

```py
>>> r = requests.post('http://localhost:5000/pay',
...    {'account': 'hacker', 'dollars': 100, 'memo': 'Auto-pay'},
...    cookies={'username': 'brandon'})
>>> print(r.url)
http://localhost:5000/?flash=Payment+successful
```

这招奏效了——100 美元已经从`brandon`账户支付给了他们控制下的一个人。

教训是，cookies 永远不应该被设计成用户可以自己创建一个。假设您的用户很聪明，如果您所做的只是用 base-64 编码模糊他们的用户名，或者交换字母，或者用常量掩码对值执行简单的异或运算，他们最终会明白的。创建不可伪造的 cookies 有三种安全的方法。

*   您可以让 cookie 可读，但要用数字签名来签名。这让攻击者感到沮丧。他们可以看到 cookie 中有他们的用户名，并希望他们可以用他们想要劫持的帐户的用户名重写用户名。但是因为他们不能伪造数字签名来签署这个新版本的 cookie，所以他们不能使您的站点相信重写的 cookie 是合法的。
*   您可以完全加密 cookie，这样用户甚至无法解释它的值。它将显示为他们无法解析或理解的不透明值。
*   您可以使用标准的 UUID 库为 cookie 创建一个没有内在含义的纯粹随机的字符串，并将其保存在您自己的数据库中，这样当用户发出下一个请求时，您就可以识别出该 cookie 是属于用户的。如果来自同一个用户的几个连续的 HTTP 请求可能最终被转发到不同的服务器，那么您的所有前端 web 机器都需要能够访问这个持久会话存储。一些应用将会话放在主数据库中，而另一些应用使用 Redis 实例或其他短期存储来防止增加主持久数据存储的查询负载。

对于这个示例应用，您可以利用 Flask 的内置功能对 cookies 进行数字签名，这样它们就不会被伪造。在真实的生产服务器上，您可能希望将签名密钥与源代码安全地分开，但是对于本例，它可以放在源文件的顶部附近。将密钥包含在生产系统的源代码中不仅会将密钥泄露给任何能够访问您的版本控制系统的人，而且还可能会将凭证暴露给开发人员的笔记本电脑和您的持续集成过程。

```py
app.secret_key = 'saiGeij8AiS2ahleahMo5dahveixuV3J'
```

Flask 会在每次你使用它的特殊的`session`对象设置一个 cookie 时使用这个密钥，比如在登录时。

```py
session['username'] = username
session['csrf_token'] = uuid.uuid4().hex
```

Flask 将在信任从传入请求中提取的任何 cookie 值之前再次使用该密钥。签名不正确的 cookie 被认为是伪造的，并被视为根本不存在于请求中。

```py
username = session.get('username')
```

您将在清单 11-8 中看到这些改进。

对 cookies 的另一个担心是，它们永远不应该通过未加密的 HTTP 通道传递，因为这样一来，在同一个咖啡店无线网络上的其他所有人都可以看到它们。许多网站小心翼翼地使用 HTTP 安全登录页面设置 cookies，只是为了在浏览器从同一个主机名提取所有 CSS、JavaScript 和图像时完全暴露它们。

为了防止暴露 cookie，了解如何让您的 web 框架在发送到浏览器的每个 cookie 上设置`Secure`参数。然后，它会小心不要将它包含在对资源的未加密请求中，无论如何每个人都可以访问这些资源。

非持久性跨站点脚本

如果对手不能窃取或伪造一个 cookie，让他们的浏览器(或 Python 程序)代表另一个用户执行操作，那么他们就可以改变策略。如果他们能想出如何控制另一个登录用户的浏览器，那么他们甚至永远也不会看到 cookie。通过使用该浏览器执行操作，cookie 将自动包含在每个请求中。

对于这种攻击，至少有三种众所周知的方法。清单 11-2 中的服务器容易受到这三种攻击，现在你将依次了解它们。

第一种类型是*跨站点脚本* (XSS)的*非持久性*版本，在这种版本中，攻击者想出如何让一个网站——就像示例支付系统——呈现攻击者编写的内容，就好像它来自该网站一样。假设攻击者想要向他们控制的账户发送 110 美元。他们可能会编写清单 11-7 中[所示的 JavaScript。](#list7)

[***清单 11-7***](#_list7) 。用于支付的脚本`attack.js`

```py
<script>
var x = new XMLHttpRequest();
x.open('POST', 'http://localhost:5000/pay');
x.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');
x.send('account=hacker&dollars=110&memo=Theft');
</script>
```

如果当用户登录到支付应用时，这个代码仅仅出现在页面上，那么它所描述的 POST 请求将自动发出，并代表无辜的用户进行支付。因为在查看呈现的网页时，`<script>`标记内的代码是不可见的，所以用户甚至不会发现有什么问题，除非他们按 Ctrl+U 查看源代码——即使这样，他们也必须将`<script>`元素识别为不寻常的东西，通常不是页面的一部分。

但是攻击者如何让这个 HTML 出现呢？

答案是攻击者可以简单地通过代码插入的`flash`参数将这个 HTML 原始地插入到`/`页面的页面模板中！因为[清单 11-2](#list2) 的作者没有阅读足够的文档，他们没有意识到原始形式的 Jinja2 不会自动转义特殊字符，如`<`和`>`，因为它不知道——除非有人告诉它——你正在用它来编写 HTML。

攻击者可以构建一个 URL，其`flash`参数包含他们的脚本。

```py
>>> with open('/home/brandon/fopnp/py3/chapter11/attack.js') as f:
...    query = {'flash': f.read().strip().replace('\n', ' ')}
>>> print('http://localhost:5000/?' + urlencode(query))
http://localhost:5000/?flash=%3Cscript%3E+var+x+%3D+new+XMLHttpRequest%28%29%3B+x.open%28%27POST%27%2C+%27http%3A%2F%2Flocalhost%3A5000%2Fpay%27%29%3B+x.setRequestHeader%28%27Content-Type%27%2C+%27application%2Fx-www-form-urlencoded%27%29%3B+x.send%28%27account%3Dhacker%26dollars%3D110%26memo%3DTheft%27%29%3B+%3C%2Fscript%3E
```

最后，攻击者需要设计一种方法来引诱用户查看并点击链接。

当瞄准一个特定的用户时，这可能是困难的。攻击者可能需要伪造一封看起来像是来自用户的一个真正朋友的电子邮件，在用户想要点击的文本后面隐藏着链接。需要研究，失效模式很多。攻击者可能会登录到用户正在聊天的 IRC 频道，并说该链接是一篇关于用户刚刚发表意见的主题的“文章”。在后一种情况下，攻击者通常会共享一个缩短的链接，只有当用户单击它时，该链接才会扩展到 XSS 链接，因为看到之前显示的完整链接可能会使用户产生怀疑。

然而，当不针对特定用户和大型站点时，例如数百万人使用的支付处理系统，攻击者通常不太具体。嵌入在发送给数百万人的诱人垃圾邮件中的有毒链接可能会让登录支付系统的人点击几下，从而为攻击者带来收入。

尝试使用前面给出的请求代码生成链接。然后点击它，无论你是否登录到支付网站。

当您登录后，您应该会发现——每次重新加载主页时——会出现另一笔付款，由您访问过的链接本身自动为您执行。在 Firefox 或 Google Chrome 中按 Ctrl+U，可以看到 JavaScript 和周围的`<script>`标签已经完整地进入页面。

如果您发现攻击不起作用，请在浏览器中打开 JavaScript 控制台。我的 Chrome 版本足够复杂，能够检测并取消攻击:“XSS 审计员拒绝执行脚本...因为在请求中找到了它的源代码。只有当这种保护被关闭或者如果攻击者找到一种更邪恶的方法来利用 flash 消息，一个好的现代浏览器才能被这里发起的攻击的原始版本所欺骗。

即使攻击成功，出现一个没有任何信息的空白绿色消息框可能会让用户感到可疑。作为一个练习，尝试修复之前 URL 中的这个缺陷:在脚本标记之外，看看是否可以提供一点像“欢迎回来”这样的真实文本，这将使绿色消息区域看起来更容易被接受。

对清单 11-8 中[攻击的防御是从 URL 中完全删除 flash 消息——这一点关于`/pay`表单刚刚完成的内容的上下文信息，应用希望在用户访问的下一个页面上显示。相反，您可以将 flash 消息保存在服务器端，直到下一个请求到来。像大多数框架一样，Flask 已经在它的函数对`flash()`和`get_flashed_messages()`T5】中为此提供了一种机制。](#list8)

持久的跨站点脚本

如果不能通过又长又难看的 URL 设置 flash 消息，攻击者将不得不通过其他机制注入 JavaScript。浏览主页时，他们的目光可能会落在显示付款的备忘录字段上。他们可以在备忘录中输入什么字符？

当然，让备忘录出现在你的页面上比在他们可以匿名提供给你的 URL 中提供备忘录要困难得多。攻击者必须使用伪造的凭证在网站上注册，或者侵入另一个用户的账户，以便向您发送一笔付款，该付款的 Memo 字段包含清单 11-7 中的[元素和 JavaScript。](#list7)

你可以自己注入这样的代码。使用你在[清单 11-2](#list2) 中看到的密码，以`sam`的身份登录应用，然后试着给我发一笔付款。附上一张漂亮的小纸条，说明你很喜欢这本书，并且给了我额外的小费。这样，我就不会怀疑你的付款了。一旦您添加了脚本元素，但在您单击“发送资金”之前，字段将类似于以下内容:

```py
To account: brandon
Dollars:    1
Memo:       A small thank-you.<script>...</script>
```

现在按提交按钮。然后注销，以`brandon`的身份重新登录，开始点击 Reload。每当`brandon`用户访问首页时，又会从他的账户中支付一笔费用！

如您所见，这种*持续*版本的跨站点脚本攻击非常强大。虽然之前创建的链接只有在用户点击时才起作用，但持久版本 JavaScript 现在以不可见的方式出现，并在用户每次访问网站时运行——将反复出现，直到服务器上的数据被清除或删除。当 XSS 攻击通过易受攻击网站上的公共形式消息发起时，它们已经影响了成百上千的用户，直到最终被修复。

[清单 11-2](#list2) 易受这个问题攻击的原因是它的作者在没有真正理解 Jinja2 模板的情况下使用了它们。他们的文件清楚地表明，他们不会自动逃脱。只有你知道打开它的转义，Jinja2 才会保护像`<`和`>`这样在 HTML 中比较特殊的字符。

[清单 11-8](#list8) 将通过 Flask `render_template()`函数调用 Jinja2 来抵御所有 XSS 攻击，当它看到模板文件名以扩展名`html`结尾时，将自动打开 HTML 转义。通过依赖 web 框架的通用模式，而不是自己做事情，您可以选择能够保护您免受不谨慎的设计决策影响的模式。

跨站请求伪造

现在，您的网站上的所有内容都被正确地屏蔽了，XSS 攻击应该不再是一个问题。但是攻击者还有一个锦囊妙计:试图从一个完全不同的站点提交表单，因为他们没有理由从您的站点启动表单。他们可以提前预测所有字段值需要是什么，因此他们可以从您可能访问的任何其他网页自由地向`/pay`发出请求。

他们所要做的就是邀请你访问一个他们隐藏了 JavaScript 的页面，或者如果他们发现你在一个没有正确地从论坛评论中转义或删除脚本标签的站点上参与了一个论坛主题，就把它嵌入到一个评论中。

您可能认为攻击者需要构建一个准备好向他们汇款的表单，然后让它的按钮成为鼠标的诱人目标。

```py
<form method="post" action="http://localhost:5000/pay">
  <input type="hidden" name="account" value="sam">
  <input type="hidden" name="dollars" value="220">
  <input type="hidden" name="message" value="Someone won big">
  <button type="submit">Reply</button>
</form>
```

然而，由于你的浏览器可能打开了 JavaScript，他们可能只需将清单 11-7 中的`<script>`元素插入到你要加载的页面、论坛帖子或页面评论中，然后坐等付款出现在他们的账户中。

这是一种典型的*跨站点请求伪造* (CSRF)攻击，它不需要攻击者想出如何破坏支付系统。所需要的是易于与世界上任何地方的任何网站组合的支付表单，攻击者可以在该网站上添加 JavaScript，并且您可能会访问该网站。您访问的每个网站都需要安全，以防范这种注射的可能性。

因此，应用需要防范它。

应用如何防止 CSRF 攻击？通过使表格难以填写和提交。他们需要一个额外的包含秘密的字段，只有表单的合法用户或他们的浏览器才能看到，而不是用支付所需的最少字段来制作简单的表单；它不需要对通过浏览器阅读和使用表单的用户可见。因为攻击者不知道任何特定用户在他们提交的每个`/pay`表单中隐藏的值，所以攻击者无法伪造一个服务器会相信的到那个地址的帖子。

同样，[清单 11-8](#list8) 将使用 Flask 将秘密安全放入 cookie 的能力，在每次用户登录时为他们分配一个秘密随机字符串。当然，这个例子要求你想象一个支付站点在现实生活中会受到 HTTPS 的保护，这样在网页或 cookie 中传递秘密是安全的，在传输过程中不会被发现。

选择了每个会话的随机秘密后，支付网站可以将它无形地添加到呈现给用户的每个`/pay`表单中。出于 CSRF 保护等原因，隐藏表单域是 HTML 的一个内置特性。以下字段被添加到`pay2.html`中的表格，替换[清单 11-8](#list8) 将使用的[清单 11-6](#list6) :

```py
<input name="csrf_token" type="hidden" value="{{ csrf_token }}">
```

每次提交表单时都会进行额外的检查，以确保表单中的 CSRF 值与表单的 HTML 版本中提交给用户的值相匹配。如果它们不匹配，那么站点认为攻击者试图代表用户提交表单，并以 403 Forbidden 拒绝该尝试。

清单 11-8 中的 CSRF 保护是手动完成的，这样你可以看到移动的部分，并理解随机选择的额外字段是如何让攻击者无法猜测如何构建一个有效的表单的。在现实生活中，您应该会发现 CSRF 保护内置于您选择的任何 web 框架中，或者至少作为一个标准插件提供。Flask 社区提出了几种方法，其中一种内置于流行的 Flask-WTF 库中，用于构建和解析 HTML 表单。

改进的应用

清单 11-8 中的[的名字是`app_improved.py`，并不“完美”或“安全”,因为坦率地说，很难证明任何特定的示例程序真的完全没有可能的漏洞。](#list8)

[***清单 11-8***](#_list8) 。`app_improved.py`付款申请

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/app_improved.py
# A payments application with basic security improvements added.

import bank, uuid
from flask import (Flask, abort, flash, get_flashed_messages,
                   redirect, render_template, request, session, url_for)

app = Flask(__name__)
app.secret_key = 'saiGeij8AiS2ahleahMo5dahveixuV3J'

@app.route('/login', methods=['GET', 'POST'])
def login():
    username = request.form.get('username', '')
    password = request.form.get('password', '')
    if request.method == 'POST':
        if (username, password) in [('brandon', 'atigdng'), ('sam', 'xyzzy')]:
            session['username'] = username
            session['csrf_token'] = uuid.uuid4().hex
            return redirect(url_for('index'))
    return render_template('login.html', username=username)

@app.route('/logout')
def logout():
    session.pop('username', None)
    return redirect(url_for('login'))

@app.route('/')
def index():
    username = session.get('username')
    if not username:
        return redirect(url_for('login'))
    payments = bank.get_payments_of(bank.open_database(), username)
    return render_template('index.html', payments=payments, username=username,
                           flash_messages=get_flashed_messages())

@app.route('/pay', methods=['GET', 'POST'])
def pay():
    username = session.get('username')
    if not username:
        return redirect(url_for('login'))
    account = request.form.get('account', '').strip()
    dollars = request.form.get('dollars', '').strip()
    memo = request.form.get('memo', '').strip()
    complaint = None
    if request.method == 'POST':
        if request.form.get('csrf_token') != session['csrf_token']:
            abort(403)
        if account and dollars and dollars.isdigit() and memo:
            db = bank.open_database()
            bank.add_payment(db, username, account, dollars, memo)
            db.commit()
            flash('Payment successful')
            return redirect(url_for('index'))
        complaint = ('Dollars must be an integer' if not dollars.isdigit()
                     else 'Please fill in all three fields')
    return render_template('pay2.html', complaint=complaint, account=account,
                           dollars=dollars, memo=memo,
                           csrf_token=session['csrf_token'])

if __name__ == '__main__':
    app.debug = True
    app.run()
```

在我写这篇文章的时候，Shellshock 漏洞刚刚被公布:在过去的 22 年里，没有人注意到，广泛使用的 Bash shell 愿意运行作为特殊格式的环境变量呈现给它的任何代码——就像旧的 CGI 机制很乐意根据输入的不可信 HTTP 头设置的那些代码。如果在二十多年后，主要的生产软件可能容易受到意想不到的特性和交互的攻击，那么我很难保证我专门为本章编写的演示 web 应用的绝对安全性。

但这是清单。它的模板进行了适当的转义，它使用内部存储来存储 flash 消息，而不是通过用户的浏览器来回发送它们，并且在它呈现给用户的每个表单中隐藏了一个随机 UUID，使得它们不可能被伪造。

请注意，两个主要的改进——切换到内部存储的 flash 消息和要求 Jinja2 在将字符添加到 HTML 之前进行适当的字符转义——是通过使用 Flask 中已经内置的标准机制而不是依赖我自己的代码实现的。

这说明了重要的一点。如果您通读框架文档并尽可能多地利用它的特性，那么您的应用不仅通常会更短、更简洁、更方便编写，而且通常会更安全，因为您将使用由专业人员编写并由 web 框架的整个社区精心改进的模式。在许多情况下，这些便利将解决您可能甚至没有意识到的安全性或性能问题。

当应用与网络交互时，它现在已经相当自动化了。但是当涉及到视图和表单的处理时，仍然有许多漏洞。

代码必须手动检查用户是否登录。每个表单字段都需要从请求中手动复制到 HTML 中，这样用户就不需要重新输入。与数据库的对话是令人失望的低层次；如果您希望 SQLite 永久记录付款，您必须自己打开数据库会话，然后记得提交。

Flask 社区中有很好的最佳实践和第三方工具，您可以求助于它们来解决这些常见的模式。相反，为了多样化，最后一个例子将是在一个框架中编写的同一个应用，它从第一天起就把这些责任从你身上拿走了。

Django 中的支付应用

Django web 框架可能是当今 Python 程序员中最受欢迎的，因为它是一个“全栈”web 框架，内置了编程新手需要的所有东西。Django 不仅有一个模板系统和 URL 路由框架，而且它还可以为您与数据库对话，将结果呈现为 Python 对象，甚至在不需要单一第三方库的情况下编写和解释表单。在一个许多 Web 编程人员几乎没有受过培训的世界里，一个建立一致和安全模式的框架可能比一个更灵活的工具更有价值，这种工具让程序员寻找他们自己的 ORM 和表单库，而他们可能甚至不清楚这些部分如何组合在一起。

您可以在本书的源代码库中找到完整的 Django 应用。同样，这是本章的网址:

```py
https://github.com/brandon-rhodes/fopnp/tree/m/py3/chapter11
```

有几个样板文件不值得在这本书的页面中全文引用。

*   `manage.py`:这是一个位于`chapter11/`目录中的可执行脚本，允许您运行 Django 命令，以开发模式设置和启动应用，稍后您将看到这一点。
*   `djbank/__init__.py`:这是一个空文件，告诉 Python 这个目录是一个 Python 包，可以从这个包中加载模块。
*   `djbank/admin.py`:这包含三行代码，使`Payment`模型出现在管理界面中，如下面的“选择 Web 框架”一节所述。
*   `djbank/settings.py`:它包含管理应用如何加载和运行的插件和配置。我对 Django 1.7 编写的缺省值所做的唯一更改是最后一行，它将 Django 指向主`chapter11/`目录中的`static/`文件目录，这样 Django 应用就可以共享由[清单 11-2](#list2) 和[清单 11-8](#list8) 使用的同一个`style.css`文件。
*   `djbank/templates/*.html`:页面模板比[清单 11-3](#list3) 到 [11-6](#list6) 中显示的 Jinja2 模板要简单一些，因为 Django 模板语言不太方便，功能也不太强大。但是，因为基本语法是相同的，所以差异不值得在本书中讨论。如果您想了解细节，请查阅两个模板系统的文档。
*   这提供了一个 WSGI callable，一个符合 WSGI 的 web 服务器，无论是 Gunicorn 还是 Apache(见第 10 章)都可以调用它来启动和运行支付应用。

剩下的四个文件很有趣，因为框架不需要任何扩展，就已经支持许多 Python 代码可以利用的常见模式。

由于内置了对象关系映射器(ORM) ，Django 免除了应用必须知道如何编写自己的 SQL 查询的麻烦。正确引用 SQL 值的整个问题也随之消失了。[清单 11-9](#list9) 通过在一个声明性的 Python 类中列出其字段来描述数据库表，该类将用于在返回时表示表行。如果您的数据限制超出了仅由字段类型所能表达的范围，Django 允许您将复杂的验证逻辑附加到这样的类上。

[***清单 11-9***](#_list9) 。Django 应用的`models.` `py`

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/djbank/models.py
# Model definitions for our Django application.

from django.db import models
from django.forms import ModelForm

class Payment(models.Model):
    debit = models.CharField(max_length=200)
    credit = models.CharField(max_length=200, verbose_name='To account')
    dollars = models.PositiveIntegerField()
    memo = models.CharField(max_length=200)

class PaymentForm(ModelForm):
    class Meta:
        model = Payment
        fields = ['credit', 'dollars', 'memo']
```

底层的类声明告诉 Django 为创建和编辑数据库行准备一个表单。它将只询问用户列出的三个字段，将`debit`字段留给您从当前登录的用户名填写。正如您将看到的，这个类能够在 web 应用与用户的对话中面向两个方向:它可以将表单呈现为一系列 HTML `<input>`字段，然后它可以返回并解析表单提交后返回的 HTTP POST 数据，以便构建或修改`Payment`数据库行。

当你使用像 Flask 这样的微框架时，你必须选择一个外部库来支持这样的操作。例如，SQLAlchemy 是一个著名的 ORM，许多程序员选择不使用 Django，这样他们就可以享受 SQLAlchemy 的强大和优雅。

但是 SQLAlchemy 本身并不了解 HTML 表单，所以使用微框架的程序员需要找到另一个第三方库来完成前面的`models.py`文件为 Django 程序员所做的另一半工作。

Django 没有让程序员使用 Flask 风格的装饰器将 URL 路径附加到 Python 视图函数，而是让应用编写人员创建一个类似于清单 11-10 中的[所示的`urls.py`文件。虽然这使得每个单独的视图在单独阅读时上下文少了一些，但它使每个视图独立于位置，并致力于集中控制 URL 空间。](#list10)

[***清单 11-10***](#_list10) 。Django 应用的`urls.` `py`

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/djbank/urls.py
# URL patterns for our Django application.

from django.conf.urls import patterns, include, url
from django.contrib import admin
from django.contrib.auth.views import login

urlpatterns = patterns('',
    url(r'^admin/', include(admin.site.urls)),
    url(r'^accounts/login/$', login),
    url(r'^$', 'djbank.views.index_view', name='index'),
    url(r'^pay/$', 'djbank.views.pay_view', name='pay'),
    url(r'^logout/$', 'djbank.views.logout_view'),
    )
```

Django 做了一个奇怪的决定，使用正则表达式匹配来匹配 URL，当一个 URL 包含几个可变部分时，这会导致难以阅读的模式。它们也很难调试，这是我的经验之谈。

这些模式基本上建立了与早期 Flask 应用相同的 URL 空间，除了到登录页面的路径是 Django 认证模块期望它所在的位置。这段代码依赖于标准的 Django 登录页面，而不是编写您自己的登录页面——并希望您写得正确，没有一些微妙的安全缺陷。

清单 11-11 中最终将 Django 应用联系在一起的视图比 Flask 版本的应用中相应的视图既简单又复杂。

[***清单 11-11***](#_list11) 。Django 应用的`views.` `py`

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/djbank/views.py
# A function for each view in our Django application.

from django.contrib import messages
from django.contrib.auth.decorators import login_required
from django.contrib.auth import logout
from django.db.models import Q
from django.shortcuts import redirect, render
from django.views.decorators.http import require_http_methods, require_safe
from .models import Payment, PaymentForm

def make_payment_views(payments, username):
    for p in payments:
        yield {'dollars': p.dollars, 'memo': p.memo,
               'prep': 'to' if (p.debit == username) else 'from',
               'account': p.credit if (p.debit == username) else p.debit}

@require_http_methods(['GET'])
@login_required
def index_view(request):
    username = request.user.username
    payments = Payment.objects.filter(Q(credit=username) | Q(debit=username))
    payment_views = make_payment_views(payments, username)
    return render(request, 'index.html', {'payments': payment_views})

@require_http_methods(['GET', 'POST'])
@login_required
def pay_view(request):
    form = PaymentForm(request.POST or None)
    if form.is_valid():
        payment = form.save(commit=False)
        payment.debit = request.user.username
        payment.save()
        messages.add_message(request, messages.INFO, 'Payment successful.')
        return redirect('/')
    return render(request, 'pay.html', {'form': form})

@require_http_methods(['GET'])
def logout_view(request):
    logout(request)
    return redirect('/')
```

你应该问的大问题是，跨站脚本保护在哪里？答案是，当我让 Django 用`manage.py startapp`命令为这个应用构建框架时，它被自动添加到`settings.py`中并打开！

你甚至不必知道 CSRF 保护的存在，你的表单将拒绝工作，除非你记得添加`{% csrf_token %}`到你的表单模板。如果你忘记了，Django 的开发模式显示的错误消息解释了这个需求。对于不了解所涉问题的新 web 开发人员来说，这是一个非常强大的模式:Django 的默认设置通常会保护他们免受表单和字段最常见的灾难性错误的影响，这是微框架很少能与之相比的。

这个应用中的视图在概念上比 Flask-powered 清单中的视图更简单，因为这段代码几乎依赖于内置的 Django 特性，而不是必须实现诸如登录和会话操作之类的东西。登录页面甚至没有出现，因为`urls.py`只是使用 Django 的。注销页面可以只调用`logout()`而不用担心它是如何工作的。视图可以用`@login_required`标记，不必担心用户是否登录。

与我们的 Flask 应用中的类似特性直接对应的唯一助手是 `@require_http_methods()` decorator，它为您提供了与 Flask 内置于其自己的视图 decorator 中的相同的保护，防止无效或不受支持的 HTTP 方法。

使用数据库现在非常简单。`bank.py`模块及其 SQL 已经完全消失了。Django 已经选择建立一个 SQLite 数据库——这是已经存在于`settings.py`中的默认数据库之一——并且它准备在代码从`models.py`文件中查询模型类的时候打开一个到数据库的会话。当代码在新的支付中调用`save()`时，它也会自动调用`COMMIT`，因为代码没有要求 Django 为您打开一个扩展的数据库事务。

付款表单的字段，因为表单被写成 HTML 格式，然后从 POST 参数中被拉回来，就这样消失了。按照要求，它没有指定`debit`字段，以便代码可以用当前用户名填充它。但是 Django 表单库会为您处理所有其他事情。

一个尴尬的地方是，真正属于模板的一点逻辑——围绕主页上支付显示的文字和表示的选择——现在不得不移到 Python 代码中，因为 Django 模板系统没有使逻辑易于表达。但是 Python 为您提供了相当简单的选择:`index()`视图调用一个生成器来生成关于每笔付款的信息的`dict`，将原始对象转换成模板感兴趣的值。

一些程序员对这种功能不足的模板系统感到恼火。其他人学习如何编写 Django“模板标签”，让他们从模板内部调用自己的逻辑。还有一些开发人员认为像[清单 11-11](#list11) 这样的代码从长远来看是最好的，因为为`make_payment_views()`这样的例程编写测试比为困在模板中的逻辑编写测试更容易。

要运行这个 Django 应用，请查看前面给出的链接中的[第 11 章](11.html)源代码，在 Python 3 下安装 Django 1.7，并运行以下三个命令:

```py
$ python manage.py syncdb
$ python manage.py loaddata start
$ python manage.py runserver
```

最后一个命令启动并运行后，您可以访问`http://localhost:8000/`并了解 Django 如何让您构建与本章前面使用 Flask 构建的应用非常相似的应用。

选择 Web 框架

web 框架的前景总是在像 Python 编程语言这样强大而健康的社区中不断创新。尽管这本书在短短几年内可能会显得过时，但这里有一个最流行框架的快速调查，以便让您对典型开发人员面临的选择有所了解:

*   Django :初学 web 程序员的好框架。内置了 CSRF 保护等功能。它的 ORM 和模板语言是内置的。这不仅让业余爱好者不必自己选择单独的库，还意味着所有第三方 Django 工具都可以采用一组通用的接口来处理 HTML 和数据库。Django 以其管理界面而闻名——运行[清单 11-11](#list11) 后，尝试访问`/admin`页面，查看管理员如何通过自动生成的创建、编辑和删除表单直接与数据库交互的示例！
*   *Tornado* :一个与这里列出的其他框架不同的 web 框架，因为它使用第 9 章中的异步回调模式，允许每个操作系统线程支持几十或几百个客户端连接，而不是每个线程只支持一个客户端。它的突出之处还在于它不依赖于对 WSGI 的支持——它直接支持 Web 套接字(在下一节中描述)。代价是许多库很难使用它的回调模式，所以程序员不得不寻找通常的 ORM 或数据库连接器的异步替代品。
*   烧瓶 :最流行的微框架，建立在可靠的工具之上，支持许多现代特性(如果程序员知道寻找并利用它们的话)。通常与 SQLAlchemy 或非关系数据库后端结合使用。
*   *瓶* :瓶的替代物，适合在一个单独的文件`bottle.py`中，而不需要安装几个单独的包。对于那些还没有在工作流程中使用 pip 安装工具的开发人员来说尤其具有吸引力。它的模板语言设计得特别好。
*   *Pyramid* :这是一个卓越的高性能综合，总结了旧的 Zope 和 Pylons 社区中的社区成员所学到的经验教训，是开发人员在流动的 URL 空间中工作的首选框架，就像您创作一个*内容管理系统* (CMS)时所创建的那样，用户只需点击鼠标就可以创建子文件夹和附加网页。虽然它可以支持预定义的 URL 结构以及任何以前的框架，但它可以通过支持对象遍历走得更远，其中框架本身理解您的 URL 组件正在命名 URL 正在访问的容器、内容和视图，就像文件系统路径在到达文件之前访问目录一样。

你可能会被它的名声所诱惑而选择一个 web 框架——也许是基于前面的段落，加上对他们网站的仔细阅读和你在社交媒体网站或 Stack Overflow 上看到的。

但是我将建议一个更重要的方向:如果您在本地 Python meetup 上有同事或朋友，他们已经是某个框架的支持者，并且可以通过电子邮件或 IRC 定期向您提供帮助，那么您可能希望选择该框架，而不是您更喜欢其网站或特性列表的类似框架。拥有一个已经经历过典型错误信息和误解的人的实时帮助，通常可以胜过框架的某个特定特性是否稍微更难使用。

WebSockets

由 JavaScript 驱动的网站通常希望支持内容的实时更新。如果有人发推文，那么 Twitter 希望更新你正在查看的页面，而不需要浏览器每秒轮询一次来询问是否有新内容出现。Websocket 协议(RFC 6455)是解决这个“长轮询问题”的最强大的解决方案。

早期的解决方法是可能的，比如著名的彗星技术。一种 Comet 技术是让客户机向路径发出 HTTP 请求；作为响应，服务器挂起，让套接字保持打开，并等待响应，直到实际事件(比如新的传入 tweet)最终发生并可以在响应中传递。

因为 WSGI 只支持传统的 HTTP，所以为了支持 WebSockets，您必须跳出标准 web 框架和所有兼容 WSGI 的 web 服务器的范围，比如 Gunicorn、Apache 和 nginx。

WSGI 不能做 WebSockets 的事实是独立的 Tornado 服务器框架流行的一个主要原因。

HTTP 以锁步方式运行，客户端首先发出一个请求，然后等待服务器完成响应，然后再发出另一个请求，而切换到 WebSockets 模式的套接字支持消息在任何时候双向传输，无需等待对方。当用户在屏幕上移动与网页交互时，客户机可以向服务器发送实时更新，而服务器同时发送来自其他来源的更新。

在网络上，一个 WebSocket 会话开始于一个看起来像 HTTP 请求和响应的内容，但是在它们的头和状态代码中，它们正在协商一个离开套接字上的 HTTP 的切换。一旦切换完成，一个新的数据组帧系统就会接管，详见 RFC。

WebSocket 编程通常涉及前端 JavaScript 库和服务器上运行的代码之间的大量协调工作，这不在本书讨论范围之内。一个简单的起点是`tornado.websocket`模块的文档，其中包括一段 Python 和 JavaScript 代码，它们可以通过一对对称的回调函数相互对话。查看任何关于异步前端浏览器编程的好参考资料，了解如何使用这种机制来动态更新网页。

网页抓取

通过尝试创建一个网站开始其 web 编程生涯的程序员的数量可能比通过编写自己的示例站点开始的程序员的数量要多得多。毕竟，与那些很容易想到他们想要复制的已经在网上的数据的人相比，有多少初学编程的人能够接触到大量等待在网上显示的数据呢？

关于网络抓取的第一条建议是:尽可能避免！

除了 raw scraping 之外，获取数据的方式往往还有很多。使用这样的数据源不仅对程序员来说更便宜，而且对站点本身来说也更便宜。互联网电影数据库将允许你从`www.imdb.com/interfaces`下载电影数据，这样你就可以运行好莱坞电影的统计数据，而不必强迫主网站呈现成千上万的额外页面，然后强迫你解析它们！许多网站，如 Google 和 Yahoo，为它们的核心服务提供 API，可以帮助你避免返回原始的 HTML。

如果谷歌搜索了你想要的数据，但没有找到任何下载或 API 的替代品，有一些规则要记住。搜索你的目标网站是否有一个“服务条款”页面。还要检查一个`/robots.txt`文件，它会告诉你哪些网址是为搜索引擎下载而设计的，哪些应该避免。这可以帮助你避免得到同一篇文章的几个副本，但是有不同的广告，同时也帮助网站控制它所面临的负载。

遵守服务条款和`robots.txt`也可以使你的 IP 地址不太可能因为提供过多的流量而被阻止。

在大多数情况下，抓取一个网站需要你在第九章第一节学过的所有知识，第十章第三节学过的 T2，以及这一章关于 T4 的 HTTP 和网络浏览器使用它的方式。

*   GET 和 POST 方法以及方法、路径和头如何组合形成 HTTP 请求
*   HTTP 响应的状态代码和结构，包括成功、重定向、暂时失败和永久失败之间的区别
*   基本 HTTP 身份验证—服务器响应如何要求身份验证，然后在客户端请求中提供身份验证
*   基于表单的身份验证以及它如何设置 cookiess，这些 cookie 需要出现在您的后续请求中才能被判断为可信
*   基于 JavaScript 的身份验证，登录表单直接回发到 web 服务器，而不需要浏览器本身参与表单提交
*   当你浏览网站时，隐藏的表单域，甚至新的 cookies，可以在 HTTP 响应中提供，以保护网站免受 CSRF 攻击
*   将数据附加到 URL 并对该位置执行 GET 的查询或操作与将数据直接发送到服务器并作为请求体传送的操作之间的区别
*   为来自浏览器的表单编码数据而设计的 POST URLs 与为与前端 JavaScript 代码直接交互而设计的 URL 之间的对比，因此可能期望并返回 JSON 或其他程序员友好格式的数据

抓取一个复杂的网站通常需要数小时的实验、调整，以及长时间点击浏览器的 web 开发工具来了解正在发生的事情。三个选项卡是必不可少的，一旦你右击一个页面并选择 Inspect Element，这三个选项卡在 Firefox 或 Google Chrome 中都应该可用。元素选项卡(参见[图 11-1](#Fig1) )向您显示动态文档，即使 JavaScript 已经添加和删除了一些东西，以便您可以了解哪些元素存在于哪些其他元素中。网络选项卡(参见[图 11-2](#Fig2) )让你点击重新加载并查看 HTTP 请求和响应——甚至是那些由 JavaScript 启动的请求和响应——它们一起提供了一个完整的页面。控制台可以让您看到页面遇到的任何错误，包括那些您作为用户可能没有意识到的错误。

程序员处理两种常见的自动化风格。

第一种是你撒网的地方，因为有大量的数据要下载。除了初始登录步骤获取所需 cookies 的可能性之外，这种任务往往涉及重复的 get 操作，当您从正在下载的页面中读取链接时，这些操作可能会进一步引发 GET。这种模式与网络搜索引擎用来了解每个网站上存在的页面的“蜘蛛”程序所采用的模式相同。

这些程序的术语“蜘蛛”来自早期，那时术语“T2”网“T3”仍然让人们想到蜘蛛网。

另一种风格是当你只在一两个页面上执行一个特定的目标动作，而不是想要一个网站的整个部分。这可能是因为您只需要来自特定页面的数据—可能您希望您的 shell 提示符打印来自特定天气页面的温度—或者因为您正在尝试自动执行通常需要浏览器的操作，例如向客户付款或列出昨天的信用卡交易，以便您可以查找欺诈。这通常需要对点击、表单和认证更加谨慎，并且通常需要一个成熟的浏览器来运行，而不是由 Python 本身来运行，因为银行使用页面内 JavaScript 来阻止未经授权访问账户的自动尝试。

记得在考虑释放一个自动化程序来对付它之前，检查服务条款和网站的文件。如果你的程序的行为——即使它陷入了你没有预料到的边缘情况——变得明显比普通用户点击他们停下来浏览或阅读的页面更加苛刻，你也要做好被阻止的准备。

我甚至不打算谈论 OAuth 和其他使程序员更难运行程序来完成程序员需要浏览器才能完成的事情的策略。当涉及到不熟悉的操作或协议时，尽可能多地从第三方库中寻求帮助，并仔细观察您的传出邮件头，尽量使它们与您发布表单或使用浏览器成功访问页面时看到的邮件头完全匹配。甚至用户代理领域也很重要，这取决于网站的固执己见程度！

获取页面

有三种从 Web 获取页面的方法，这样您就可以在 Python 程序中检查它们的内容。

*   使用 Python 库发出直接的 GET 或 POST 请求。使用 Requests 库作为您的首选解决方案，向它请求一个`Session`对象，这样它就可以跟踪 cookies 并为您进行连接池。如果您想留在标准库中，低复杂性情况的一个替代方法是`urllib.request`。
*   曾经有一种中间地带的工具，它们可以像原始的 web 浏览器一样工作，它们可以找到`<form>`元素，并帮助您使用浏览器将表单输入传递回服务器所使用的相同规则来构建 HTTP 请求。Mechanize 是最著名的，但是我没有发现它被维护过——可能是因为现在很多网站已经足够复杂，以至于 JavaScript 几乎是浏览现代网络的一个要求。
*   你可以使用真正的网络浏览器。在接下来的例子中，您将使用 Selenium Webdriver 库来控制 Firefox，但是使用“无头”工具的实验也在进行中，这些工具可以像浏览器一样工作，而不必打开整个窗口。它们通常通过创建一个不连接到实际窗口的 WebKit 实例来工作。PhantomJS 使这种方法在 JavaScript 社区中流行起来，而`Ghost.py`是当前将这种能力引入 Python 的一个实验。

如果你已经知道你想要访问的网址，你的算法会很简单。获取 URL 列表，对每个 URL 运行 HTTP 请求，并保存或检查其内容。只有当你事先不知道 URL 列表，并且需要边走边学的时候，事情才会变得复杂。然后你需要跟上你去过的地方，这样你就不会访问一个 URL 两次，然后永远循环下去。

[清单 11-12](#list12) 显示了一个目标明确的刮刀的适度例子。它旨在登录到支付应用，并报告用户已经获得的收入。在运行它之前，在一个窗口中启动支付程序的副本。

```py
$ python app_improved.py
```

[***清单 11-12***](#_list12) 。登录支付系统并累加收入

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/mscrape.py
# Manual scraping, that navigates to a particular page and grabs data.

import argparse, bs4, lxml.html, requests
from selenium import webdriver
from urllib.parse import urljoin

ROW = '{:>12}  {}'

def download_page_with_requests(base):
    session = requests.Session()
    response = session.post(urljoin(base, '/login'),
                            {'username': 'brandon', 'password': 'atigdng'})
    assert response.url == urljoin(base, '/')
    return response.text

def download_page_with_selenium(base):
    browser = webdriver.Firefox()
    browser.get(base)
    assert browser.current_url == urljoin(base, '/login')
    css = browser.find_element_by_css_selector
    css('input[name="username"]').send_keys('brandon')
    css('input[name="password"]').send_keys('atigdng')
    css('input[name="password"]').submit()
    assert browser.current_url == urljoin(base, '/')
    return browser.page_source

def scrape_with_soup(text):
    soup = bs4.BeautifulSoup(text)
    total = 0
    for li in soup.find_all('li', 'to'):
        dollars = int(li.get_text().split()[0].lstrip('$'))
        memo = li.find('i').get_text()
        total += dollars
        print(ROW.format(dollars, memo))
    print(ROW.format('-' * 8, '-' * 30))
    print(ROW.format(total, 'Total payments made'))

def scrape_with_lxml(text):
    root = lxml.html.document_fromstring(text)
    total = 0
    for li in root.cssselect('li.to'):
        dollars = int(li.text_content().split()[0].lstrip('$'))
        memo = li.cssselect('i')[0].text_content()
        total += dollars
        print(ROW.format(dollars, memo))
    print(ROW.format('-' * 8, '-' * 30))
    print(ROW.format(total, 'Total payments made'))

def main():
    parser = argparse.ArgumentParser(description='Scrape our payments site.')
    parser.add_argument('url', help='the URL at which to begin')
    parser.add_argument('-l', action='store_true', help='scrape using lxml')
    parser.add_argument('-s', action='store_true', help='get with selenium')
    args = parser.parse_args()
    if args.s:
        text = download_page_with_selenium(args.url)
    else:
        text = download_page_with_requests(args.url)
    if args.l:
        scrape_with_lxml(text)
    else:
        scrape_with_soup(text)

if __name__ == '__main__':
    main()
```

一旦这个 Flask 应用在端口 5000 上运行，您就可以在另一个终端窗口中启动`mscrape.py`。先安装漂亮的 Soup 第三方库，如果你的系统上没有，你也会需要请求。

```py
$ pip install beautifulsoup4
$ pip install requests
$ python mscrape.py http://127.0.0.1:5000/
         125  Registration for PyCon
         200  Payment for writing that code
    --------  ------------------------------
         325  Total payments made
```

像这样在默认模式下运行，`mscrape.py`首先使用请求库通过登录表单登录到站点。这将为`Session`对象提供成功获取首页所需的 cookie。然后，该脚本解析页面，获取用类`to`标记的列表项元素，并通过几个`print()`调用显示这些支出，同时将这些支出相加。

通过提供`-s`选项，您可以切换`mscrape.py`,让它做一些更令人兴奋的事情:运行 Firefox 的完整版本，如果它发现您的系统上安装了 Firefox，就访问网站！您将需要安装 Selenium 包才能使用这种模式。

```py
$ pip install selenium
$ python mscrape.py -s http://127.0.0.1:5000/
         125  Registration for PyCon
         200  Payment for writing that code
    --------  ------------------------------
         325  Total payments made
```

一旦脚本打印出输出，您可以按 Ctrl+W 来关闭 Firefox。虽然您可以编写 Selenium 脚本，让它们自动关闭 Firefox，但我更喜欢在编写和调试时让它保持打开，这样我就可以在程序出错时看到浏览器中出现了什么问题。

这两种方法之间的差异值得强调。要编写使用请求的代码，您需要自己打开网站，研究登录表单，并将您在那里找到的信息复制到`post()`方法用来登录的数据中。一旦这样做了，您的代码就无法知道登录表单将来是否会改变。它将简单地继续使用硬编码的输入名称`'username'`和`'password'`，不管它们是否仍然相关。

所以，请求方法，至少在这样写的时候，真的不像浏览器。打开登录页面并在那里看到一个表单是没有意义的。更确切地说，它假设登录页面存在，并绕过它运行一次，以发布作为其结果的表单。显然，如果登录表单被赋予了一个秘密令牌来防止大量猜测用户密码的尝试，这种方法就会失效。在这种情况下，您将需要添加对`/login`页面本身的第一个 GET，以获取需要与您的用户名和密码相结合的秘密令牌，从而生成有效的帖子。

`mscape.py`中的基于硒的代码采取了相反的方法。就像用户坐在浏览器前一样，它的行为就好像只是看到一个表单，选择它的元素并开始输入。然后它到达并点击按钮提交表单。只要它的 CSS 选择器继续正确识别表单字段，代码就能成功登录，不管有什么秘密标记或特殊的 JavaScript 代码来签署或自动化表单发布，因为 Selenium 只是在 Firefox 中做与登录完全一样的事情。

当然，Selenium 比 Requests 慢得多，尤其是当您第一次启动它并且必须等待 Firefox 启动时。但是它可以快速执行一些操作，否则使用 Python 可能需要几个小时的实验。一种解决困难的抓取工作的有趣方法可以是一种混合方法:您能否使用 Selenium 登录并获得必要的 cookies，然后告诉请求关于它们的信息，这样您对更多页面的大量获取就不需要在浏览器上等待了？

抓取页面

当一个站点以 CSV、JSON 或其他一些可识别的数据格式返回数据时，您当然会使用标准库中或第三方库中的相应模块对其进行解析，以便能够对其进行处理。但是如果您需要的信息隐藏在面向用户的 HTML 中呢？

在谷歌 Chrome 或 Firefox 中按下 Ctrl+U 后阅读原始 HTML 可能会很累，这取决于网站选择的格式。右键单击，选择 Inspect Element，然后愉快地浏览浏览器看到的可折叠的元素文档树，这通常更令人愉快——假设 HTML 格式正确，并且标记中的错误没有隐藏浏览器中需要的数据！正如您已经看到的，live element inspector 的问题是，当您看到文档时，在网页中运行的任何 JavaScript 程序可能已经将它编辑得面目全非了。

查看这样的页面至少有两个简单的技巧。第一种方法是关闭浏览器中的 JavaScript，然后点击重新加载您正在阅读的页面。它现在应该会重新出现在元素检查器中，但没有进行任何更改:您应该会看到 Python 代码在下载相同文档时会看到的内容。

另一个技巧是使用某种“整洁”的程序，就像 W3C 发布的，可以在 Debian 和 Ubuntu 上以`tidy`包的形式获得。原来清单 11-12 中使用的两个解析库都内置了这样的例程。一旦`soup`对象存在，您就可以使用以下有用的缩进在屏幕上显示它的元素:

```py
print(soup.prettify())
```

lxml 文档树需要更多的工作来显示。

```py
from lxml import etree
print(etree.tostring(root, pretty_print=True).decode('ascii'))
```

无论哪种方式，如果提供 HTML 的站点没有将元素放在单独的行上并缩进它们以使它们的文档结构清晰，结果可能比原始 HTML 更容易阅读——当然，这些步骤可能不方便，并且会增加任何提供 HTML 的站点的带宽需求。

检查 HTML 包括以下三个步骤:

1.  要求您选择的库解析 HTML。这对图书馆来说可能很困难，因为网络上的许多 HTML 包含错误和损坏的标记。但是设计者通常不会注意到这一点，因为浏览器总是试图恢复和理解标记。毕竟，哪个浏览器供应商会希望自己的浏览器是唯一一个返回某个流行网站错误的浏览器，而其他所有浏览器都正常显示呢？清单 11-12 中使用的两个库都以健壮的 HTML 解析器而闻名。
2.  使用*选择器*进入文档，这些选择器是文本模式，会自动找到您想要的元素。虽然您可以自己动手，慢慢地遍历每个元素的子元素，寻找您感兴趣的标签和属性，但是使用选择器通常要快得多。它们通常还会产生更清晰、更易读的 Python 代码。
3.  向每个元素对象询问所需的文本和属性值。然后，您又回到了普通 Python 字符串的世界，可以使用所有普通字符串方法对数据进行后处理。

这个三阶段过程在清单 11-12 中使用两个独立的库执行了两次。

`scrape_with_soup()`函数使用古老的 BeautifulSoup 库，这是全世界程序员的首选资源。它的 API 古怪而独特，因为它是第一个让 Python 中的文档解析如此方便的库，但它确实完成了任务。

所有的“soup”对象，无论是代表整个文档的对象还是代表单个元素的从属对象，都提供了一个`find_all()`方法,用于搜索与给定标签名和可选的 HTML 类名相匹配的从属元素。 `get_text()`方法可以在您最终到达您想要的底部元素并准备好读取其内容时使用。仅用这两种方法，代码就能从这个简单的网站中获取数据，甚至复杂的网站也常常只需六个或十几个单独的步骤就能完成。

完整的 BeautifulSoup 文档可在`www.crummy.com/software/BeautifulSoup/`在线获取。

`scrape_with_lxml()`函数使用了构建在 libxml2 和 libxslt 之上的现代快速 lxml 库。如果您使用的是没有安装编译器的传统操作系统，或者如果您没有安装操作系统可能支持编译的 Python 包的`python-dev`或`python-devel`包，那么安装起来可能会很困难。Debian 衍生的操作系统已经将针对系统 Python 编译的库作为一个包，通常简称为 python-lxml。

像 Anaconda 这样的现代 Python 发行版已经编译好了 lxml，可以安装在 Mac OS X 和 Windows 上。

如果你能够安装它，清单 11-12 可以使用这个库来解析 HTML。

```py
$ pip install lxml
$ python mscrape.py -l http://127.0.0.1:5000/
         125  Registration for PyCon
         200  Payment for writing that code
    --------  ------------------------------
         325  Total payments made
```

同样，基本操作步骤与 BeautifulSoup 相同。您从文档的顶部开始，使用 find 或 search 方法——在本例中是`cssselect()`——来锁定您感兴趣的元素，然后使用进一步的搜索来获取从属元素，或者最后向元素询问它们所包含的文本，以便您可以解析和显示它。

lxml 不仅比 BeautifulSoup 快，而且它还提供了许多选择元素的选项。

*   它用`cssselect()`支持 CSS 模式。这在按类查找元素时尤其重要，因为无论元素的类属性是写为`class="x"`、`class="x y"`还是`class="w x"`，它都被认为是在类`x`中。
*   它用它的`xpath()`方法支持 XPath 表达式，受到 XML 爱好者的喜爱。例如，它们看起来像`'.//p'`来查找所有段落。XPath 表达式的一个有趣的方面是，您可以用`'.../text()'`结束它，并简单地获取每个元素内部的文本，而不是获取 Python 对象，然后您必须请求它们内部的文本。
*   它本身通过其`find()`和`findall()`方法支持 XPath 操作的快速子集。

请注意，在这两种情况下，scraper 必须做一些工作，因为付款描述字段是它自己的`<i>`元素，但网站设计者没有将每行开头的美元金额放在它自己的元素中。这是一个相当典型的问题；你想从页面中得到的一些东西会很方便地单独放在一个元素中，而另一些会放在其他文本的中间，需要你使用传统的 Python 字符串方法，比如`split()`和`strip()` 来把它们从上下文中解救出来。

递归抓取

这本书的源代码库包括一个小的静态网站，使得 web 抓取器很难到达它的所有页面。您可以在这里在线观看:

```py
https://github.com/brandon-rhodes/fopnp/tree/m/py3/chapter11/tinysite/
```

如果您已经签出了源代码存储库，那么您可以使用 Python 的内置 web 服务器在您自己的机器上提供它。

```py
$ cd py3/chapter11/tinysite
$ python -m http.server
Serving HTTP on 0.0.0.0 port 8000 ...
```

如果您查看页面源代码，然后使用浏览器的 web 调试工具环顾四周，您会发现并不是首页上的所有链接在`http://127.0.0.1:8000/`都是在同一时刻提交的。事实上，只有两个(“page1”和“page2”)在页面的原始 HTML 中作为具有`href=""`属性的真正锚标记出现。

接下来的两个页面位于带有搜索提交按钮的表单后面，除非单击该按钮，否则无法访问它们。

最后两个链接(“第 5 页”和“第 6 页”)出现在屏幕底部，是一小段动态 JavaScript 代码的结果。这模拟了网站的行为，这些网站快速地向您显示页面的框架，但是在您感兴趣的数据出现之前又向服务器做了一次往返。

在这一点上——你想对一个网站上的所有 URL 甚至只是其中的一部分进行全面的递归搜索——你可能想去寻找一个可以帮助你的网络抓取引擎。与 web 框架从 web 应用中提取常见模式的方式一样，比如需要为不存在的页面返回 404，抓取框架知道如何跟踪已经访问过的页面以及哪些页面仍需要访问。

目前最流行的网络抓取工具是 Scrapy ( `http://scrapy.org/`)，如果你想尝试以一种适合其模型的方式描述一个抓取任务，你可以研究它的文档。

在[清单 11-13](#list13) 中，你可以看看幕后，看看一个真实的——如果简单的话——铲运机下面是什么样子。这个库需要 lxml，所以如果可能的话，安装第三方库，如前一节所述。

[***清单 11-13***](#_list13) 。简单的递归 Web Scraper 得到了

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/rscrape1.py
# Recursive scraper built using the Requests library.

import argparse, requests
from urllib.parse import urljoin, urlsplit
from lxml import etree

def GET(url):
    response = requests.get(url)
    if response.headers.get('Content-Type', '').split(';')[0] != 'text/html':
        return
    text = response.text
    try:
        html = etree.HTML(text)
    except Exception as e:
        print('    {}: {}'.format(e.__class__.__name__, e))
        return
    links = html.findall('.//a[@href]')
    for link in links:
        yield GET, urljoin(url, link.attrib['href'])

def scrape(start, url_filter):
    further_work = {start}
    already_seen = {start}
    while further_work:
        call_tuple = further_work.pop()
        function, url, *etc = call_tuple
        print(function.__name__, url, *etc)
        for call_tuple in function(url, *etc):
            if call_tuple in already_seen:
                continue
            already_seen.add(call_tuple)
            function, url, *etc = call_tuple
            if not url_filter(url):
                continue
            further_work.add(call_tuple)

def main(GET):
    parser = argparse.ArgumentParser(description='Scrape a simple site.')
    parser.add_argument('url', help='the URL at which to begin')
    start_url = parser.parse_args().url
    starting_netloc = urlsplit(start_url).netloc
    url_filter = (lambda url: urlsplit(url).netloc == starting_netloc)
    scrape((GET, start_url), url_filter)

if __name__ == '__main__':
    main(GET)
```

除了启动和读取其命令行参数的任务之外，[清单 11-13](#list13) 只有两个移动的部分。最简单的是它的`GET()`函数，尝试下载一个 URL，如果类型是 HTML 就尝试解析；只有在这些步骤成功的情况下，它才会获取所有锚标签(`<a>`)的`href=""`属性，以了解当前页面链接到的其他页面。因为这些链接中的任何一个都可能是相对 URL，所以它在每个链接上调用`urljoin()`来提供它们可能缺少的任何基本组件。

对于`GET()`函数在页面文本中发现的每个 URL，它返回一个元组，表明它希望抓取引擎在它发现的 URL 上调用自己，除非引擎知道它已经这样做了。

引擎本身只需要跟上它已经调用的函数和 URL 的组合，以便在网站上反复出现的 URL 只被访问一次。它保存一组它以前见过的 URL 和另一组还没有访问过的 URL，并继续循环，直到后一组最终为空。

你可以在一个大型公共网站上运行这个 scraper，比如 httpbin。

```py
$ python rscrape1.py http://httpbin.org/
```

或者你可以在一个小的静态站点上运行它，这个站点的 web 服务器是你在几段前启动的——唉，这个抓取器只会找到两个链接，这两个链接实际上是由 HTTP 响应第一次提交的。

```py
$ python rscrape1.py http://127.0.0.1:8000/
GET http://127.0.0.1:8000/
GET http://127.0.0.1:8000/page1.html
GET http://127.0.0.1:8000/page2.html
```

如果刮刀要看到更多，需要两种成分。

首先，您需要在真实的浏览器中加载 HTML，以便 JavaScript 可以运行并加载页面的其余部分。

第二，除了`GET()`之外，你还需要进行第二次操作，深呼吸，点击搜索按钮，看看它背后有什么。

这种操作在任何情况下都不应该成为自动抓取器的一部分，自动抓取器是用来从公共网站上抓取一般内容的，因为正如您现在所了解到的，表单提交是专门为用户操作设计的，尤其是在有 POST 操作支持的情况下。(在这种情况下，表单执行 GET，因此至少安全一点。)然而，在这种情况下，您已经研究了这个小网站，并得出结论，点击按钮应该是安全的。

请注意，清单 11-14 可以简单地重用前一个 scraper 的引擎，因为该引擎没有紧密地耦合到它应该调用什么函数的任何特定观点。它将调用作为工作提交给它的任何函数。

[***清单 11-14***](#_list14) 。用 Selenium 递归抓取网站

```py
#!/usr/bin/env python3
# Foundations of Python Network Programming, Third Edition
# https://github.com/brandon-rhodes/fopnp/blob/m/py3/chapter11/rscrape2.py
# Recursive scraper built using the Selenium Webdriver.

from urllib.parse import urljoin
from rscrape1 import main
from selenium import webdriver

class WebdriverVisitor:
    def __init__(self):
        self.browser = webdriver.Firefox()

    def GET(self, url):
        self.browser.get(url)
        yield from self.parse()
        if self.browser.find_elements_by_xpath('.//form'):
            yield self.submit_form, url

    def parse(self):
        # (Could also parse page.source with lxml yourself, as in scraper1.py)
        url = self.browser.current_url
        links = self.browser.find_elements_by_xpath('.//a[@href]')
        for link in links:
            yield self.GET, urljoin(url, link.get_attribute('href'))

    def submit_form(self, url):
        self.browser.get(url)
        self.browser.find_element_by_xpath('.//form').submit()
        yield from self.parse()

if __name__ == '__main__':
    main(WebdriverVisitor().GET)
```

因为创建 Selenium 实例的成本很高——毕竟它们必须启动 Firefox 的副本——所以您不敢在每次需要获取 URL 时都调用`Firefox()`方法。相反，`GET()`例程在这里被编写为一个方法，而不是一个裸函数，这样浏览器属性可以从一个`GET()`调用延续到下一个，并且在您准备调用`submit_form()`时也是可用的。

`submit_form()`方法 是这个清单与前一个清单真正不同的地方。当`GET()`方法看到页面上的搜索表单时，它会向引擎发回一个附加的元组。除了为它在页面上看到的每个链接生成一个元组之外，它还会生成一个元组来加载页面并单击大搜索按钮。这就是为什么这个刮刀比前一个更深入这个地方。

```py
$ python rscrape2.py http://127.0.0.1:8000/
GET http://127.0.0.1:8000/
GET http://127.0.0.1:8000/page1.html
GET http://127.0.0.1:8000/page2.html
submit_form http://127.0.0.1:8000/
GET http://127.0.0.1:8000/page5.html
GET http://127.0.0.1:8000/page6.html
GET http://127.0.0.1:8000/page4.html
GET http://127.0.0.1:8000/page3.html
```

因此，尽管有些链接是通过 JavaScript 动态加载的，而其他链接只能通过表单发布才能到达，scraper 还是能够找到网站上的每一个页面。通过这种强大的技术，您应该会发现您与任何网站的交互都可以通过 Python 实现自动化。

摘要

HTTP 的设计是为了提供万维网:一个由超链接互连的文档集合，每个文档都指定了另一个页面或页面的一部分的 URL，只需单击超链接的文本就可以访问该页面。Python 标准库提供了一些有用的例程，用于解析和构建 URL，以及将部分“相对 URL”转换为绝对 URL，方法是用来自出现它们的页面的基本 URL 的信息填充任何不完整的组件。

Web 应用通常使用响应传入 HTTP 请求的代码连接一些持久数据存储，如数据库，并作为响应构建 HTML 页面。当您试图从 Web 上插入不可信的信息时，让数据库自己进行引用是至关重要的，并且 DB-API 2.0 和您可能在 Python 中使用的任何 ORM 都会小心地正确进行引用。

Web 框架的范围从简单到全栈。有了一个简单的框架，你可以自己选择模板语言和 ORM 或其他持久层。一个全栈框架将提供这些工具的自己的版本。在这两种情况下，将 URL 连接到您自己的代码的一些方法将是可用的，这些方法既支持静态 URL，也支持像`/person/123/`这样的 URL，其路径组件可以变化。还将提供呈现和返回模板以及返回重定向或 HTTP 错误的快速方法。

每个网站作者面临的巨大危险是，在像 Web 这样的复杂系统中，组件交互的许多方式可能会让用户颠覆你自己的意图或彼此的意图。在外部世界和您自己的代码之间的接口上，跨站点脚本攻击、跨站点请求伪造和对您的用户隐私的攻击的可能性都必须牢记在心。在编写代码接受来自 URL 路径、URL 查询字符串、POST 或文件上传的数据之前，应该彻底了解这些危险。

框架之间的权衡通常是在一个像 Django 这样的全栈解决方案和一个像 Flash 或 Bottle 这样的解决方案之间进行选择，前者鼓励您使用它的工具集，但倾向于为您选择好的默认设置(比如在表单中自动打开 CSRF 保护)，后者感觉更时尚、更轻便，并允许您组装自己的解决方案，但这需要您预先了解所需的所有部分。如果你在 Flask 中编写一个应用，只是不知道你需要 CSRF 保护，你将没有它。

Tornado 框架因其异步方法而脱颖而出，该方法允许从单个操作系统级别的控制线程为许多客户端提供服务。随着 Python 3 中`asyncio`的出现，像 Tornado 这样的方法有望朝着一组通用的习惯用法发展，就像今天 WSGI 已经为线程化 web 框架提供的那些习惯用法一样。

翻转和抓取网页需要对网站的正常工作方式有透彻的了解，这样通常的用户交互就可以被编写成脚本，包括登录、填写和提交表单等复杂操作。Python 中有几种获取页面和解析页面的方法。此时，用于获取的请求或 Selenium 和用于解析的 BeautifulSoup 或 lxml 是最受欢迎的。

因此，通过对 web 应用编写和抓取的研究，本书完成了对 HTTP 和万维网的覆盖。下一章开始了对 Python 标准库中支持的几个不太为人所知的协议的浏览，转到了电子邮件的主题以及它们是如何被格式化的。